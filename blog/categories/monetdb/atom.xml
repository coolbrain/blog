<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: MonetDB | ForgeBrain]]></title>
  <link href="http://coolbrain.github.com/blog/categories/monetdb/atom.xml" rel="self"/>
  <link href="http://coolbrain.github.com/"/>
  <updated>2013-10-17T04:34:25+08:00</updated>
  <id>http://coolbrain.github.com/</id>
  <author>
    <name><![CDATA[ForgeBrain]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[MonetDB VS PostgreSQL数据库]]></title>
    <link href="http://coolbrain.github.com/blog/2013/04/28/monetdb-vs-postgresql/"/>
    <updated>2013-04-28T19:43:00+08:00</updated>
    <id>http://coolbrain.github.com/blog/2013/04/28/monetdb-vs-postgresql</id>
    <content type="html"><![CDATA[<blockquote><p><p>MonetDB与PostgreSQL数据库的架构比较，虽然它们存储结构有本质的区别，一个以列存储，一个以行存储；一个没有索引，一个有多种类型的索引，B+树索引，Hash索引，GiST索引等。但它们也有很多的类似之处。</p>
<!-- more -->
<p><strong>PostgreSQL的进程结构：</strong></p>
<p>PostgreSQL系统的主要功能都集中于Postgres程序，其入口是Main模块中的main函数，在初始化数据集簇，启动数据库服务器时，都将从这里开始。Main模块主要的工作是确定当前的操作系统平台，并据此做一些平台相关的环境变量设置和初始化。然后通过对命令行参数的判断，将控制转到相应的模块中去。图是PostgreSQL系统主函数main的流程.</p>
<img src="/assets/images/PostgresqlProcess.jpg" alt="&quot;postgresqlProcess&quot;" />
<p>PostgreSQL使用一种专用服务器进程体系结构，其中，最主要的两个进程就是守护进程Postmaster和服务进程Postgres。从本质上来说，Postmaster和Postgres都是通过装入Postgres程序而形成的进程，只是在运行时所处的分支不同而已。守护进程Postmaster负责整个系统的启动和关闭。它监听并接受客户端的连接请求，为其分配服务进程Postgres.服务进程Postgres接受并执行客户端发送的命令。它在底层模块（如存储，事务管理，索引等）之上调用各个主要的功能模块（如编译器，优化器，执行器等）(如下图所示），完成客户端的各种数据库操作，并返回执行结果。</p>
<img src="/assets/images/postgresql.jpg" alt="&quot;postgresql&quot;" />
<p>PostgreSQL守护进程Postmaster（单用户模式的Postgres进程）除为用户连接请求分配后台Postgres服务进程外，还将启动相关的后台辅助进程。守护进程Postmaster在完成基本环境初始化，创建接受用户请求的监听端口后，顺序启动如下系统辅助进程：SysLogger（系统日志进程）、PsStat（统计数据收集进程）、AutoVacuum（系统自动清理进程）。在守护进程Postmaster进入到循环监听中启动如下进程：BgWriter（后台写进程）、WalWriter（预写式日志写进程），PgArch（预写式日志归档进程）。</p>
<p><strong>守护进程PostMaster：</strong></p>
<p>Postmaster就像一个处理客户端请求的调度中心。当客户端程序需要对数据库进行操作时，首先会发出一个起始消息给Postmaster进行请求。Postmaster将根据这个起始消息中的信息对客户端进行验证，如果身份验证通过，Postmaster就为该客户端新建一个服务进程Postgres。随后Postmaster将与客户端的交互工作转交给Postgres服务进程，由Postgres来完成客户端所需要的数据库操作。</p>
<p>PostgreSQL请求--响应模型</p>
<img src="/assets/images/postmaster.jpg" alt="&quot;postmaster&quot;" />
<p>Postmaster也负责管理整个系统范围的操作，例如中断等操作，Postmaster本身不进行这些操作，它只是指派一个子进程在适当的时间去处理它们。同时它要在数据库崩溃的时候重启系统。Postmaster进程在起始时会建立共享内存和信号库，<strong>Postmaster及其子进程的通信就通过共享内存和信号</strong>来实现。这种多进程设计使得整个系统的稳定性更好，即使某个后台进程崩溃也不会影响系统中其他进程的工作，Postmaster只需要重置共享内存即可从单个后台进程的崩溃中恢复。</p></p></blockquote>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[基于Memo-based(日志)的查询执行]]></title>
    <link href="http://coolbrain.github.com/blog/2013/04/26/memo-based-query-execution/"/>
    <updated>2013-04-26T22:57:00+08:00</updated>
    <id>http://coolbrain.github.com/blog/2013/04/26/memo-based-query-execution</id>
    <content type="html"><![CDATA[<blockquote><p><p>现代以代价为基础的查询优化器使用备忘录结构为一个有效的查询运行计划组织搜索空间。例如，考虑一个oid连接路径‘A.B.C.D’.我们可以在这条路径任何点启动计算。它的备忘录结构可以用一个（大）MAL程序来表示。备忘录的水平用choice运算封装。第二个参数指示哪些指令去被考虑代价计算。</p>
<!-- more -->
{% codeblock  lang:c %}
...
scheduler.choice("getVolume");
T1:= algebra.join(A,B);
T2:= algebra.join(B,C);
T3:= algebra.join(C,D);
scheduler.choice("getVolume",T1,T2,T3);
T4:= algebra.join(T1,C);
T5:= algebra.join(A,T2);
T6:= algebra.join(T2,D);
T7:= algebra.join(B,T3);
T8:= algebra.join(C,D);
scheduler.choice("getVolume",T4,T5,T6,T7,T8);
T9:= algebra.join(T4,D);
T10:= algebra.join(T5,D);
T11:= algebra.join(A,T6);
T12:= algebra.join(A,T7);
T13:= algebra.join(T1,T8);
scheduler.choice("getVolume",T9,T10,T11,T12,T13);
answer:= scheduler.pick(T9, T10, T11, T12, T13);
{% endcodeblock %}
<p>scheduler.choice()操作为每个目标变量调用内置的getVolume且期待一个整数值代价。在这个事例里它返回总共参数使用的字节数。具有最低代价的目标变量被选择运行和剩余的变量被变成临时NOOP操作（你可能想重用备忘录）。它们会被解析器遗漏，同时在接下的调用中被调度器忽略。它减少了替换当我们在计划中处理时。一个内置朴素的代价函数会被使用。使用者可以提供一个私有的代价函数被定义为目标和a :lng结果带有多态参数的模式。它的实现可以使用完全的上下文信息去做决定。如，它可以跟踪在接下的语句中对目标变量的潜在使用去决定总代价当这一步被考虑到最后的结果。</p>
<p>在达到下个选择点前，一个完整计划很可能包含其他表达式去准备或使用目标变量。choice运算的任务是避免不必要的操作。MAL块应该被调用者私有拥有，这样确保了scheduler.isolation()。模式的细化也组成部分计划代价分析。然后你不再需要包含一个固定的代价函数。</p>
{% codeblock  lang:c %}
Acost:= aggr.count(A);
Bcost:= aggr.count(B);
Ccost:= aggr.count(C);
T1cost:= Acost+Bcost;
T2cost:= Bcost+Ccost;
T3cost:= Ccost+Dcost;
scheduler.choice(T1cost,T1, T2cost,T2, T3cost,T3);
T1:= algebra.join(A,B);
T2:= algebra.join(B,C);
T3:= algebra.join(C,D);
{% endcodeblock %}
{% codeblock MonetDB中RunChoice的实现代码 lang:c %}
/<em>THe choice operator first searches the next one to identify
  the fragment to be optimized and to gain access to the variables
  without the need to declare them upfront.</em>/
str  RUNchoice(Client cntxt, MalBlkPtr mb, MalStkPtr stk, InstrPtr p)
{</p>

<pre><code>int target;
lng cost, mincost;
int i, j, pc;
char *nme;
InstrPtr q;
</code></pre></blockquote>

<pre><code>pc = getPC(mb, p);
for (i = pc + 1; i &lt; mb-&gt;stop; i++) {
    q = getInstrPtr(mb, i);
    if (getModuleId(p) == getModuleId(q) &amp;&amp;
        getFunctionId(p) == getFunctionId(q)) {
        p = q;
        break;
    }
}
if (i == mb-&gt;stop)
    return MAL_SUCCEED;
target = getArg(p, 2);
if (getArgType(mb, p, 1) == TYPE_int &amp;&amp; p-&gt;argc &gt;= 3 &amp;&amp; (p-&gt;argc - 1) % 2 == 0) {
    /* choice pairs */
    mincost = *(int *) getArgReference(stk, p, 1);
    for (i = 3; i &lt; p-&gt;argc; i += 2) {
        cost = *(int *) getArgReference(stk, p, i);
        if (cost &lt; mincost &amp;&amp; !isVarDisabled(mb, getArg(p, i + 1))) {
            mincost = cost;
            target = getArg(p, i + 1);
        }
    }
} else if (getArgType(mb, p, 1) == TYPE_str) {
    nme = *(str *) getArgReference(stk, p, 1);
    /* should be generalized to allow an arbitrary user defined function */
    if (strcmp(nme, "getVolume") != 0)
        throw(MAL, "scheduler.choice", ILLEGAL_ARGUMENT "Illegal cost function");

    mincost = -1;
    for (j = 2; j &lt; p-&gt;argc; j++) {
        if (!isVarDisabled(mb, getArg(p, j)))
            for (i = pc + 1; i &lt; mb-&gt;stop; i++) {
                InstrPtr q = getInstrPtr(mb, i);
                if (p-&gt;token &gt;= 0 &amp;&amp; getArg(q, 0) == getArg(p, j)) {
                    cost = getVolume(stk, q, 1);
                    if (cost &gt; 0 &amp;&amp; (cost &lt; mincost || mincost == -1)) {
                        mincost = cost;
                        target = getArg(p, j);
                    }
                    break;
                }
            }

    }
}
</code></pre>

<h1>ifdef DEBUG_RUN_MEMORUN</h1>

<pre><code>mnstr_printf(cntxt-&gt;fdout, "#function target %s cost %d\n", getVarName(mb, target), mincost);
</code></pre>

<h1>else</h1>

<pre><code>(void) cntxt;
</code></pre>

<h1>endif</h1>

<pre><code>/* remove non-qualifying variables */
for (i = 2; i &lt; p-&gt;argc; i += 2)
    if (getArg(p, i) != target) {
        setVarDisabled(mb, getArg(p, i - 1));
        setVarDisabled(mb, getArg(p, i));
    }

propagateNonTarget(mb, pc + 1);
</code></pre>

<h1>ifdef DEBUG_RUN_MEMORUN</h1>

<pre><code>mnstr_printf(cntxt-&gt;fdout, "#cost choice selected %s %d\n",
        getVarName(mb, target), mincost);
printFunction(cntxt-&gt;fdout, mb, 1);
</code></pre>

<h1>endif</h1>

<pre><code>return MAL_SUCCEED;
</code></pre>

<p>}
{% endcodeblock %}</p>

<blockquote><p><p><strong>1.合并表优化：</strong></p>
<p>一个合并相关表（MAT）描述符定义了一个可兼容BAT的有序的类型集合，它的并代表一个单一（虚）BAT。MAL可能代表一个分区的BAT（看BPM），也可以是一个在一个程序块中临时BATs的任意集合。MAL的定义存在于一个单代码块的范围。MAT优化简单地扩展计划去基于指令的基础上处理它的模块。只有当遇上一个blocking操作时，相关的BAT才会被实例化。当没有被实例化，MAL对象不能作为参数传入到任何函数。简单地说，因为MAL不被类型系统所知道和没有底层的操作意识到它的存在。</p>
<p>在MAL优化器的第一种方法中，我们假设在MAT序列中第一个BAT被使用累加器。进一步，没有语义知识被使用去减少可能无用的连接。然而，我们限制对一个简单参数的扩展。这在后阶段被改变当一个以代价为基础的计算被用于区分不同的。为了说明，考虑：</p>
{% codeblock  lang:c %}
m0:= bat.new(:oid,:int);
m1:= bat.new(:oid,:int);
m2:= bat.new(:oid,:int);
b := mat.new(m0,m1,m2);
s := algebra.select(b,1,3);
i := aggr.count(s);
io.print(s);
io.print(i);
c0 := bat.new(:int,:int);
c1 := bat.new(:int,:int);
c := mat.new(c0,c1);
j := algebra.join(b,c);
io.print(j);
{% endcodeblock %}
<p>选择和聚集操作可以使用MAT简单地重写：</p>
{% codeblock  lang:c %}
<em>33 := algebra.select(m0,1,3);
</em>34 := algebra.select(m1,1,3);
<em>35 := algebra.select(m2,1,3);
s := mat.new(</em>33,<em>34,</em>35);
i := 0:int;
<em>36 := aggr.count(</em>33);
i := calc.+(i,<em>36);
</em>37 := aggr.count(<em>34);
i := calc.+(i,</em>37);
<em>38 := aggr.count(</em>35);
i := calc.+(i,<em>38);
io.print(i);
{% endcodeblock %}
<p>print操作还没有MAT语义。它需要一个在调用时不会产生头的函数。然而，在输出前，我们可以打包元素：</p>
{% codeblock  lang:c %}
s := mat.pack(</em>33,<em>34,</em>35);
io.print(s);
{% endcodeblock %}
<p>对于连接，在不知道人和关于组件属性的情况下，我们必须生成所有可能的组合。当前的启发是限制扩展一个简单的参数。这导致：</p>
{% codeblock  lang:c %}
b := mat.pack(m0,m1,m2);
<em>39 := algebra.join(b,c0);
</em>40 := algebra.join(b,c1);
j := mat.new(<em>39,</em>40);
{% endcodeblock %}
<p>这模式的不足是在MAL语句中隐藏爆炸。优化器的挑战从对MAT元素的属性的监测中找出最小的。如，在处理前，它可能尝试去部分地打包元素。这是一个运行调度的决定。相反的，在更复杂的程序分析中毕竟系统可以使用MAT迭代器去避免打包.</p>
{% codeblock  lang:c %}
ji:= bat.new(:oid,:int);
barrier b:= mat.newIterator(m0,m1,m2);
barrier c:= mat.newIterator(c0,c1);
ji := algebra.join(b,c);
bat.insert(j,ji);
redo c:= mat.newIterator(c0,c1);
redo b:= mat.newIterator(m0,m1,m2);
exit c;
exit b;
{% endcodeblock %}
{% codeblock MonetDB合并表优化实现 lang:c %}
int  OPTmergetableImplementation(Client cntxt, MalBlkPtr mb, MalStkPtr stk, InstrPtr p)
{</p>

<pre><code>InstrPtr *old=0, q;
mat_t *mat;
int oldtop, fm, i, k, m, mtop=0, slimit;
int size, match, actions=0, error=0;
</code></pre></blockquote>

<pre><code>(void) cntxt;
/* the number of MATs is limited to the variable stack*/
mat = (mat_t*) GDKzalloc(mb-&gt;vtop * sizeof(mat_t));
if ( mat == NULL)
    return 0;

old = mb-&gt;stmt;
oldtop= mb-&gt;stop;
slimit = mb-&gt;ssize;
size = (mb-&gt;stop * 1.2 &lt; mb-&gt;ssize)? mb-&gt;ssize:(int)(mb-&gt;stop * 1.2);
mb-&gt;stmt = (InstrPtr *) GDKzalloc(size * sizeof(InstrPtr));
if ( mb-&gt;stmt == NULL){
    mb-&gt;stmt = old;
    return 0;
}
mb-&gt;ssize = size;
mb-&gt;stop = 0;

for( i=0; i&lt;oldtop; i++){
    int n = -1, o = -1;

    p = old[i];
    if (getModuleId(p) == matRef &amp;&amp; 
       (getFunctionId(p) == newRef || getFunctionId(p) == packRef)){
        mtop = mat_add(mat, mtop, p, NULL, mat_none, 1);
        continue;
    }

    if (getModuleId(p) == batcalcRef &amp;&amp;
       (getFunctionId(p) == mark_grpRef ||
       getFunctionId(p) == dense_rank_grpRef)) { 
        /* Mergetable cannot handle 
           order related batcalc operations */
        error++;
        goto fail;
    }
    /*
     * @-
     * If the instruction does not contain MAT references it can simply be added.
     * Otherwise we have to decide on either packing them or replacement.
     */
    if ((match = MATcount(p, mat, mtop)) == 0) {
        if (p-&gt;argc &gt;= 2) {
            if (getFunctionId(p) == markHRef|| 
                getFunctionId(p) == markTRef) {
                propagateMarkProp(mb, p, getArg(p,1), 0, oid_nil);
            } else if (getFunctionId(p) == leftjoinRef|| 
                   getFunctionId(p) == joinRef|| 
                       getFunctionId(p) == kunionRef) {
                propagateBinProp(mb, p, getArg(p,1), getArg(p,2));
            } else {
                propagateProp(mb, p, getArg(p,1));
            }
        }
        pushInstruction(mb, copyInstruction(p));
        continue;
    }
    /*
     * @-
     * Here we handle horizontal aligned mats. This information is passed using
     * the properties hlb &lt;= x &lt; hub.
     * So if this is available, we can simplify
     * batcalc operations and for fetch joins we can use this information to do
     * per part joins only.
     *
     * Also we should translate the mirror().join() (a groupby attribute) into
     * UNION(mirror().join()).
     */

    /* only handle simple joins, ie not range/band joins */
    /* For range/band joins (argc == 4), the propagation of oids
       is different, ie result-head equals head-1st arg,    
                result-tail equals head-2nd/3rd arg */

    /* TODO:
       If a value join with mats on both sides fails (ie unknown
       how to handle) we should bail out, ie stop any further
       processing of any mats. This is needed because the needed 
       mas-crossproduct handling of projections fails. 
             */
    if (match &gt; 0 &amp;&amp; match &lt;= 2 &amp;&amp; isMatJoinOp(p) &amp;&amp; 
       (p-&gt;argc == 3 || (p-&gt;argc == 4 &amp;&amp; getFunctionId(p) == thetajoinRef))) {
        int om, tpe = mat_none;

        om = m = isMATalias(getArg(p,1), mat, mtop);
        if (om &lt; 0) { /* range join with parts on the right */
            error++;
            goto fail;
        }

        n = isMATalias(getArg(p,2), mat, mtop);
        if (isProjection(p) &amp;&amp; m &gt;= 0 &amp;&amp; mat_is_topn(mat[m].type))
            tpe = mat_tpn;
        if (isProjection(p) &amp;&amp; m &gt;= 0 &amp;&amp; mat_is_orderby(mat[m].type))
            tpe = mat_rdr;

        if ((m = mat_join(mb, p, mat, mtop, m, n)) &lt; 0) {
            error++;
            goto fail;
        } else
            mtop = m;
        /* after topn projection we should merge */
        /* slice marks the end of a sequence of topn's */
        if (tpe == mat_tpn &amp;&amp; (getFunctionId(old[i+1]) == sliceRef || mat[om].type == mat_slc))
            mtop = mat_pack_topn(mb, p, mat, mtop, om);
        else if (tpe == mat_tpn &amp;&amp; mat[om].mm) 
            mtop = mat_pack_topn_project(mb, p, mat, mtop, om);

        /* after sort projection we should mat.merge */
        if (tpe == mat_rdr &amp;&amp; !mat[om].mm)
            mtop = mat_pack_sort(mb, p, mat, mtop, om, 1);
        else if (tpe == mat_rdr &amp;&amp; mat[om].mm) 
            mtop = mat_pack_sort_project(mb, p, mat, mtop, om);
        actions++;
        continue;
    }
    /* all map operations assume aligned bats */
    if (match &gt;= 1 &amp;&amp; all_mats_and_aligned(mb, p, mat, mtop) &amp;&amp;
       isMapOp(p)) {
        mtop = mat_map(mb, p, mat, mtop); 
        actions++;
        continue;
    }
    if (match &gt;= 1 &amp;&amp;
        getModuleId(p) == algebraRef &amp;&amp;
        getFunctionId(p)== kunionRef) {
        m = isMATalias(getArg(p,1), mat, mtop);
        n = isMATalias(getArg(p,2), mat, mtop);
        mtop = mat_union(mb, p, mat, mtop, m, n);
        actions++;
        continue;
    } 
    if (match &gt;= 1 &amp;&amp; 
        (getModuleId(p) == algebraRef &amp;&amp; 
         ((getFunctionId(p) == semijoinRef &amp;&amp; match == 2) ||
          (getFunctionId(p) == kdifferenceRef)))) { 
        i += mat_setop(mb, p, mat, &amp;mtop); 
        actions++;
        continue;
    }
    /*
     * @-
     * Now we handle group, derive and aggregation statements.
     */
    if (match == 1 &amp;&amp; p-&gt;argc == 3 &amp;&amp; getModuleId(p) == groupRef &amp;&amp; 
       (getFunctionId(p) == newRef || getFunctionId(p) == doneRef) &amp;&amp; 
       ((m=isMATalias(getArg(p,2), mat, mtop)) &gt;= 0)) {
        if (mat[m].mi1 || mat[m].mm) {
            /* group on finished group is fine */
            if (mat[m].mm) {
                pushInstruction(mb, copyInstruction(p));
                actions++;
                continue;
            }
            /* two phase group.new on group result */
            error++;
            goto fail;
        }
        mtop = mat_group_new(mb, p, mat, mtop, m);
        actions++;
        continue;
    }
    if (match == 3 &amp;&amp; p-&gt;argc == 5 &amp;&amp; getModuleId(p) == groupRef &amp;&amp; 
        (getFunctionId(p) == deriveRef || getFunctionId(p) == doneRef )
</code></pre>

<p>&amp;&amp;</p>

<pre><code>       ((m=isMATalias(getArg(p,2), mat, mtop)) &gt;= 0) &amp;&amp;
       ((n=isMATalias(getArg(p,3), mat, mtop)) &gt;= 0) &amp;&amp;
       ((o=isMATalias(getArg(p,4), mat, mtop)) &gt;= 0)) {

        /* Found a derive after an aggr statement (distinct). */
        if (mat[m].mm) {
            error++;
            goto fail;
        }

        mtop = mat_group_derive(mb, p, mat, mtop, m, n, o);
        actions++;
        continue;
    }
    if (match == 3 &amp;&amp; getModuleId(p) == aggrRef &amp;&amp; p-&gt;argc == 4 &amp;&amp;
       (getFunctionId(p) == countRef ||
        getFunctionId(p) == count_no_nilRef ||
        getFunctionId(p) == minRef ||
        getFunctionId(p) == maxRef ||
        getFunctionId(p) == sumRef ||
        getFunctionId(p) == prodRef) &amp;&amp;
       ((m=isMATalias(getArg(p,1), mat, mtop)) &gt;= 0) &amp;&amp;
       ((n=isMATalias(getArg(p,2), mat, mtop)) &gt;= 0) &amp;&amp;
       ((o=isMATalias(getArg(p,3), mat, mtop)) &gt;= 0)) {
        if (!mat_group_aggr(mb, p, mat, m, n, o)){
            error++;
            goto fail;
        }
        actions++;
        continue;
    }
    /* median */
    if (match == 3 &amp;&amp; getModuleId(p) == aggrRef &amp;&amp; p-&gt;argc == 4) {
        error++;
        goto fail;
    }
    /*
     * @-
     * Aggregate handling is a prime target for optimization.
     * The simple cases are dealt with first.
     * Handle the rewrite v:=aggr.count(b) and sum()
     * And the min/max is as easy
     */
    if (match == 1 &amp;&amp; p-&gt;argc == 2 &amp;&amp;
       ((getModuleId(p)==aggrRef &amp;&amp;
        (getFunctionId(p)== countRef || 
         getFunctionId(p)== count_no_nilRef || 
         getFunctionId(p)== minRef ||
         getFunctionId(p)== maxRef ||
         getFunctionId(p)== sumRef ||
             getFunctionId(p) == prodRef)) ||
        (getModuleId(p) == algebraRef &amp;&amp;
         getFunctionId(p) == tuniqueRef)) &amp;&amp;
        (m=isMATalias(getArg(p,1), mat, mtop)) &gt;= 0) {
        mat_aggr(mb, p, mat, m);
        actions++;
        continue;
    } 
    if (match == 1 &amp;&amp; p-&gt;argc == 3 &amp;&amp; isTopn(p) &amp;&amp;
       (m=isMATalias(getArg(p,1), mat, mtop)) &gt;= 0 &amp;&amp;
       mat[m].type == mat_none) {
        mtop = mat_topn(mb, p, mat, mtop, m);
        actions++;
        continue;
    }
    if (match == 1 &amp;&amp; p-&gt;argc == 4 &amp;&amp; isSlice(p) &amp;&amp;
       (m=isMATalias(getArg(p,1), mat, mtop)) &gt;= 0 &amp;&amp;
       mat[m].type == mat_none) {
        mtop = mat_topn(mb, p, mat, mtop, m);
        actions++;
        continue;
    }
    if (match == 2 &amp;&amp; p-&gt;argc == 4 &amp;&amp; isTopn(p) &amp;&amp;
       (m=isMATalias(getArg(p,1), mat, mtop)) &gt;= 0 &amp;&amp;
       (n=isMATalias(getArg(p,2), mat, mtop)) &gt;= 0 &amp;&amp;
        mat_is_topn(mat[n].type) &amp;&amp;
        mat_is_topn(mat[m].type) &amp;&amp; !mat[m].mm) {
        mtop = mat_topn2(mb, p, mat, mtop, m, n);
        actions++;
        continue;
    }
    if (match == 1 &amp;&amp; p-&gt;argc == 2 &amp;&amp; isOrderby(p) &amp;&amp;
       (m=isMATalias(getArg(p,1), mat, mtop)) &gt;=0 &amp;&amp;
       mat[m].type == mat_none) {
        mtop = mat_sort(mb, p, mat, mtop, m);
        actions++;
        continue;
    }
    /* TODO: grp before sorting, isn't handled */
    if (match == 1 &amp;&amp; p-&gt;argc == 2 &amp;&amp; isOrderby(p) &amp;&amp;
       (m=isMATalias(getArg(p,1), mat, mtop)) &gt;=0 &amp;&amp;
       mat[m].type == mat_grp) {
        assert(mat[m].mm); /* should be packed */
        error++;
        goto fail;
    }
    if (match == 2 &amp;&amp; p-&gt;argc == 3 &amp;&amp; isOrderby(p) &amp;&amp;
       (m=isMATalias(getArg(p,1), mat, mtop)) &gt;= 0 &amp;&amp;
       (n=isMATalias(getArg(p,2), mat, mtop)) &gt;= 0 &amp;&amp;
        /*mat_is_orderby(mat[n].type) &amp;&amp;*/
        mat_is_orderby(mat[m].type) &amp;&amp; !mat[m].mm) {
        mtop = mat_sort2(mb, p, mat, mtop, m, n);
        actions++;
        continue;
    }
    if (match == 1 &amp;&amp; p-&gt;argc == 4 &amp;&amp; getModuleId(p) == sqlRef &amp;&amp; 
        getFunctionId(p) == resultSetRef &amp;&amp; 
       (m=isMATalias(getArg(p,3), mat, mtop)) &gt;= 0 &amp;&amp;
        mat_is_orderby(mat[m].type) &amp;&amp; !mat[m].mm) {
        mtop = mat_pack_sort(mb, p, mat, mtop, m, 0);
        actions++;
        continue;
    }
    /*
     * @-
     * The slice operation can also be piggy backed onto the mat.pack using it
     * as a property of the MAT. Pushing it through
     * would be feasible as well, provided the start of the slice is a constant 0.
     */
    if (match &gt; 0 &amp;&amp; getModuleId(p) == algebraRef &amp;&amp;
            getFunctionId(p) == sliceRef &amp;&amp;
            (m = isMATalias(getArg(p, 1), mat, mtop)) &gt;= 0)
    {
        assert(0);
        /* inject new mat.pack() operation */
        q = MATpackAll(mb, NULL, mat, m, &amp;mtop);
        /* rename mat.pack() to mat.slice() */
        setFunctionId(q, sliceRef);
        /* insert bounds from algebra.slice() into mat.slice() */
        /* (setArgument() seems to shift the remaining arguments,
         *  i.e., insert a new argument, not overwrite an existing one) */
        q = setArgument(mb, q, 1, getArg(p, 2));
        q = setArgument(mb, q, 2, getArg(p, 3));
        /* reuse result variable of algebra.slice() for mat.slice() */
        /* (we do not explicitly keep, and thus drop, the original algebra.slice()) */
        getArg(q, 0) = getArg(p, 0);

        actions++;
        continue;
    }
    /*
     * @-
     * The mark operators are a special case of apply on parts as we need to
     * correct the mark base oid's
     */
    if (match == 1 &amp;&amp; 
        getModuleId(p) == algebraRef &amp;&amp; 
        (getFunctionId(p) == markTRef ||
         getFunctionId(p) == markHRef)) { 
        InstrPtr mark;

        m = isMATalias(getArg(p,1), mat, mtop);
        mark = mat_mark(mb, p, mat, m);
        mtop = mat_add(mat, mtop, mark, NULL, useMatType(mat, m), 0);
        actions++;
        continue;
    }
    /*
     * @-
     * Pack MAT arguments, except one, to limit plan explosion.
     * The preferred partitioned one is the first argment as it
     * often reflects a base table.
     * Look at the depth of the MAT definition to limit the explosion.
     */
    for( fm= p-&gt;argc-1; fm&gt;p-&gt;retc ; fm--)
        if ((m=isMATalias(getArg(p,fm), mat, mtop)) &gt;= 0)
            break;
    /*
     * @-
     * Not all instructions can be replaced by the sequence. We have to
     * group them and check for them individually.
     */
    if (match == 1 &amp;&amp; isDiffOp(p) &amp;&amp; fm == 1 &amp;&amp; 
       (m=isMATalias(getArg(p,fm), mat, mtop)) &gt;= 0){
        InstrPtr r;

        if ((r = mat_apply1(mb, p, mat, m, fm, 0)) != NULL)
            mtop = mat_add(mat, mtop, r, NULL, mat_none, 0);
        actions++;
        continue;
    }
    if (match == 1 &amp;&amp; 
       isUpdateInstruction(p) &amp;&amp; getModuleId(p) == sqlRef &amp;&amp; 
       (m=isMATalias(getArg(p,fm), mat, mtop)) &gt;= 0) {
        mat_update(mb, p, mat, m, fm);
        actions++;
        continue;
    }
    if (match == 1 &amp;&amp; 
       isFragmentGroup(p) &amp;&amp; 
       (m=isMATalias(getArg(p,fm), mat, mtop)) &gt;= 0){
        int pack_mirror = 0;
        InstrPtr r;

        OPTDEBUGmergetable mnstr_printf(GDKout, "# %s.%s\n", getModuleId(p), getFunctionId(p));

        if (getFunctionId(p) == mirrorRef &amp;&amp; 
                mat[m].type == mat_grp/* &amp;&amp; mat[m].mm */) {
            assert(mat[m].mm != NULL);
            pack_mirror = 1;
        }

        if (group_broken(p, mat[m].type, pack_mirror)) {
            error++;
            goto fail;
        }

        if ((r = mat_apply1(mb, p, mat, m, fm, 0)) != NULL)
            mtop = mat_add(mat, mtop, r, NULL, useMatType(mat, m), 0);

        /* packed group should include the mirror statement */
        if (pack_mirror) {
            if (mat[m].mv1 == p-&gt;argv[1])  {
                assert(0);
                mat[mtop-1].type = mat_grp;
            } else
                mat[mtop-1].type = mat_ext;
            mat_pack_group(mb, mat, m, mtop-1);
        }
        actions++;
        continue;
    } 
    /*
     * @-
     * All other instructions should be checked for remaining MAT dependencies.
     * It requires MAT materialization.
     */
    OPTDEBUGmergetable mnstr_printf(GDKout, "# %s.%s %d\n", getModuleId(p), getFunctionId(p), match);


    for (k = p-&gt;retc; k&lt;p-&gt;argc; k++) {
        if((m=isMATalias(getArg(p,k), mat, mtop)) &gt;= 0){
            if (MATpackAll2(mb, NULL, mat, m, &amp;mtop) &lt; 0){
                error++;
                goto fail;
            }
            actions++;
        }
    }
    pushInstruction(mb, copyInstruction(p));
    if (p-&gt;argc &gt;= 2)
        propagateProp(mb, p, getArg(p,1));
}
/*
 * @-
 * As a final optimization, we could remove the mal.new definitions,
 * because they are not needed for the execution.
 * For the time being, they are no-ops.
 */
(void) stk; 
chkTypes(cntxt-&gt;fdout, cntxt-&gt;nspace,mb, TRUE);

OPTDEBUGmergetable {
    mnstr_printf(GDKout,"#Result of multi table optimizer\n");
    (void) optimizerCheck(cntxt,mb,"merge test",1,0,0);
    printFunction(GDKout, mb, 0, LIST_MAL_ALL);
}

if ( mb-&gt;errors == 0) {
    for(i=0; i&lt;slimit; i++)
        if (old[i]) 
            freeInstruction(old[i]);
    GDKfree(old);
}
</code></pre>

<p>fail:</p>

<pre><code>if( error || mb-&gt;errors){
    actions= 0;
    OPTDEBUGmergetable 
        mnstr_printf(GDKout, "## %s.%s\n", getModuleId(p), getFunctionId(p));

    for(i=0; i&lt;mb-&gt;stop; i++)
        if (mb-&gt;stmt[i])
            freeInstruction(mb-&gt;stmt[i]);
    GDKfree(mb-&gt;stmt);
    mb-&gt;stmt = old;
    mb-&gt;ssize = slimit;
    mb-&gt;stop = oldtop;
    for(i=0; i&lt;mb-&gt;stop; i++) {
        InstrPtr p = mb-&gt;stmt[i];
        if (p &amp;&amp; getModuleId(p) == matRef &amp;&amp; getFunctionId(p) == newRef){
            /* simply drop this function, for the base binding is available */
            p-&gt;token = NOOPsymbol;
        }
    }
    OPTDEBUGmergetable mnstr_printf(GDKout,"Result of multi table optimizer FAILED\n");
}
DEBUGoptimizers
    mnstr_printf(cntxt-&gt;fdout,"#opt_mergetable: %d merge actions\n",actions);
for (i =0; i&lt;mtop; i++) {
    if (mat[i].pushed == 1)
        continue;
    if (mat[i].mi &amp;&amp; mat[i].mi-&gt;token != NOOPsymbol)
        freeInstruction(mat[i].mi);
    if (mat[i].mi1 &amp;&amp; mat[i].mi1-&gt;token != NOOPsymbol)
        freeInstruction(mat[i].mi1);
}
GDKfree(mat);
return actions;
</code></pre>

<p>}
{% endcodeblock %}</p>

<blockquote><p><p><strong>2.多道编译优化：</strong></p>
<p>MonetDB 操作多道概念是中轴的简单运用任何标量的函数的元素在一个容器里。任何操作CMD和它的多道转变【CMD】一起出现。给出CMD(T1，..,Tn)的标记：TR，它可以被使用同时【CMD】(bat[:any 1,:T1],...,bat[any 1,Tn]) :bat[any 1,Tr]。多道的语义在所有Bat值参数执行定位连接和对匹配的元组的每个组合执行CMD。所有的结果被收集在一个结果的BAT。所有但除一个参数外可能会被一个标量值替换。对多道操作通用的解决方案是把它们翻译成MAL循环。一个片段关于其行为：</p>
{% codeblock  lang:c %}
b:= bat.new(:int,:int);
bat.insert(b,1,1);
c:bat[:int,:int]:= mal.multiplex("calc.+",b,1);
optimizer.multiplex();
{% endcodeblock %}
<P>当前的实现需要目标类型要被清晰地被提到。由优化器产生的结果：<p>
{% codeblock  lang:c %}
b := bat.new(:int,:int);
bat.insert(b,1,1);
<em>8 := bat.new(:int,:int);
barrier (</em>11,<em>12,</em>13):= bat.newIterator(b);
<em>15 := calc.+(</em>13,1);
bat.insert(<em>8,</em>12,<em>15);
redo (</em>11,<em>12,</em>13):= bat.hasMoreElements(b);
exit (<em>11,</em>12,<em>13);
c := </em>8;
{% endcodeblock %}
{% codeblock MonetDB多道优化的代码实现 lang:c %}
int OPTmultiplexImplementation(Client cntxt, MalBlkPtr mb, MalStkPtr stk, InstrPtr pci)
{</p>

<pre><code>InstrPtr *old, p;
int i, limit, slimit, actions= 0;
str msg= MAL_SUCCEED;
</code></pre></blockquote>

<pre><code>(void) stk;
(void) pci;

old = mb-&gt;stmt;
limit = mb-&gt;stop;
slimit = mb-&gt;ssize;
if ( newMalBlkStmt(mb, mb-&gt;ssize) &lt; 0 )
    return 0;

for (i = 0; i &lt; limit; i++) {
    p = old[i];
    if (msg == MAL_SUCCEED &amp;&amp;
                getModuleId(p) == malRef &amp;&amp;
        getFunctionId(p) == multiplexRef) {
        msg = OPTexpandMultiplex(cntxt, mb, stk, p);
        if( msg== MAL_SUCCEED){
            freeInstruction(p);
            old[i]=0;
        } else {
            pushInstruction(mb, p);
        }
        actions++;
    } else if( old[i])
        pushInstruction(mb, p);
}
for(;i&lt;slimit; i++)
    if( old[i])
        freeInstruction(old[i]);
GDKfree(old);
DEBUGoptimizers {
    mnstr_printf(cntxt-&gt;fdout,"#opt_multiplex: %d expansions\n", actions);
    mnstr_printf(cntxt-&gt;fdout,"#mal program: %d MAL instr %d vars (" SZFMT " K)\n",mb-&gt;stop,mb-&gt;vtop,
    ((sizeof( MalBlkRecord) +mb-&gt;ssize * sizeof(InstrRecord)+ mb-&gt;vtop* sizeof(VarRecord) + mb-&gt;vsize*sizeof(VarPtr)+1023)/1024));
}
if (mb-&gt;errors){
    /* rollback */
}
return mb-&gt;errors? 0: actions;
</code></pre>

<p>}
{% endcodeblock %}</p>

<blockquote><p><p><strong>3.BAT分区优化</strong></p>
<p>在老的PC地址空间受限和分布的存储的需要使BATs理想地被看重作为更小的BATs的并集，在给定有限的内存中处理。带有支持性的bat分区库bmp的PARTITION()优化器用可适配的数据库分段算法解决这问题。它被递增地设计带有一个中心是支持SQL front-end。特别是，被考虑的操作被限制为MAL的子集。一个在这集合外面的操作的出现终止优化器的活动。OPTIMIZER.PARTITIONS()操作寻找SQL列BAT的绑定和为了使用分区版本而准备代码。</p>
<p>我们使用两种是吸纳。第一种尝试寻找线性依赖数据的片段和在其构造一个迭代器。这种方法有些棘手，因为你必须对特殊的情况进行关照。特别是，在顺序构建操作的语义造成一些问题。navie（）方法简单地看自个儿的操作和用迭代器围绕它们。一个别名的表被保留用来重用和探测已经分区的操作符。不足之处一个分区的BAT潜伏要读几次【这取决于变量可计算的重使用】和中间的读写。实验应该指明一个优化的一个。</p>
<p><strong>4.窥孔优化</strong></p>
<p>递归下降查询器很容易对产生更好的代码错失机会，因为有限的上下文被保留或向前看可用。窥孔优化器在这样递归的模式下建立和对优化器的‘错误’补救。窥孔模式的集合随着时间增长和front-end详细的变化应该可以预见。SQL frontend 严重依赖于一个中轴的生成oid序列的表。不幸的是，这是不能被看见和模式’$i := calc.oid(0@0); $j:= algebra.markT($k,$i);经常发生。这可以被’$j:= algebra.markT($k)’替换。另一个产生2-way指令序列例子是’$j:= algebra.markT($k); $l:= bat.reverse($j);’,这都可以用’$l:= algebra.markH($k);’替换。</p>
<p>reverse-reverse 操作也落入这个目录。相反的pairs 可能起因于front-end编译器的处理模式或者其它优化器步骤的副影响。这样的相反对应该越快去除越好，这样可以减小找到另外优化机会的复杂度。因所有的情况下我们应该保证被丢掉的中间结果不会被用于其他用途。</p>
{% codeblock  lang:c %}
r:bat[:int,:int]:= bat.new(:int,:int);
o:= calc.oid(0@0);
z:= algebra.markT(r,o);
rr:= bat.reverse(z);
s := bat.reverse(r);
t := bat.reverse(s);
io.print(t);
optimizer.peephole();
{% endcodeblock %}
<p>这被窥孔优化器转化为：</p>
{% codeblock  lang:c %}
r:bat[:int,:int] := bat.new(:int,:int);
rr := algebra.markH(r);
io.print(r);
{% endcodeblock %}
<p><strong>5.查询执行计划</strong></p>
<p>一个普遍使用的数据结构去表示和操作一个查询是树(或图）。它的节点表示操作符和叶子表示操作数。这样的视图随手拈来当你要重组整块代码或者去建立一个从底到上建立优化计划，如使用备忘录结构。MAL优化器工具箱提供函数用树（图）结构覆盖任何的MAL块和线性化回MAL块。线性化顺序被一个递归调用的从支撑点遍历树的决定。为了说明，考虑下列代码块：</p>
{% codeblock  lang:c %}
//T1:= bat.new(:int,:int);
//T2:= bat.new(:int,:int);
//T3:= bat.new(:int,:int);
//T4:= bat.new(:int,:int);
a:= algebra.select(T1,1,3);
b:= algebra.select(T2,1,3);
c:= algebra.select(T3,0,5);
d:= algebra.select(T4,0,5);
e:= algebra.join(a,c);
f:= algebra.join(b,d);
h:= algebra.join(e,f);
optimizer.dumpQEP();
{% endcodeblock %}
<p>这产生一个目的查询计划的结构</p>
{% codeblock  lang:c %}
h := algebra.join(e,f);</p>

<pre><code>e := algebra.join(a,c);
    a := algebra.select(T1,1,3);
        T1 := bat.new(:int,:int);
c := algebra.select(T3,0,5);
    T3 := bat.new(:int,:int);
f := algebra.join(b,d);
    b := algebra.select(T2,1,3);
        T2 := bat.new(:int,:int);
    d := algebra.select(T4,0,5);
        T4 := bat.new(:int,:int);
</code></pre>

<p>{% endcodeblock %}
<p>任何有效的MAL任务都可以被基于流依赖的树或图结构的视图覆盖，但不是所有的MAL程序都可以从一棵简单的树继承。如，上面的程序块片段被解释为线性的序列不能被表示除非执行指令自身成为操作符节点。然而，因为我们没有增加或者改变根源的MAL程序，qep.progagate任务产生原有的先行次序有优先级的程序。如果，然而，我们进入树的新的指令，它们会被放置到邻近的其它树的节点。对块的流控制给予特殊的关照，因为产生一个查询计划块不是很容易就能环绕。</p>
{% codeblock MonetDB dumpQEP的实现 lang:c %}
/<em> The core of the work is focused on building the tree using a flow analysis.
 * Building the tree means that we should not allow the same variable can not be used twice.</em>/</p>

<h1>define LEAFNODE 2</h1>

<h1>define TOPNODE 3</h1>

<p>static QEP
QEPbuilt(MalBlkPtr mb){</p>

<pre><code>QEP qroot= NULL, q= NULL, *vq;
InstrPtr p;
int i, j, k, *status;
</code></pre></blockquote>

<pre><code>vq= (QEP*) GDKmalloc( mb-&gt;vtop * sizeof(QEP));
if (vq == NULL)
    return NULL;
status= (int*) GDKmalloc( mb-&gt;vtop * sizeof(int));
if (status == NULL){
    GDKfree(vq);
    return NULL;
}
for(i=0; i&lt;mb-&gt;vtop; i++) {
    status[i]= 0;
    vq[i] = 0;
}

for(i=1; i&lt; mb-&gt;stop-1; i++){
    p= getInstrPtr(mb,i);
    q= QEPnewNode(mb,p);
    for( k=p-&gt;retc; k&lt;p-&gt;argc; k++) 
    if( ! isVarConstant(mb, getArg(p,k)) ){
        status[getArg(p,k)]= LEAFNODE;
        if( vq[getArg(p,k)] )
            QEPappend(q, vq[getArg(p,k)]);
    }
    for( k=0; k&lt;p-&gt;retc; k++){
        if( vq[getArg(p,k)] == 0)
            vq[getArg(p,k)] = q;
        status[getArg(p,k)]= TOPNODE;
    }

}
</code></pre>

<p>/<em> We may end up with multiple variables not yet bound to a QEP. </em>/</p>

<pre><code>qroot= QEPnew(MAXPARENT,mb-&gt;stop);
for(i=1; i&lt; mb-&gt;stop-1; i++){
    p= getInstrPtr(mb,i);

    k=0;
    if( p-&gt;barrier){
        k++;
        q= QEPnewNode(mb,p);
    } else
    for( j=0; j&lt; p-&gt;retc; j++)
    if( status[getArg(p,j)] == TOPNODE){
        q= vq[getArg(p,j)];
        k++;
        break;
    }
    if(k)
        QEPappend(qroot,q);
}
GDKfree(vq);
GDKfree(status);
return qroot;
</code></pre>

<p>}
/<em> It may be handy to dump the graph for inspection
 * or to prepare for the dot program.</em>/
static void
QEPdump(stream *f, QEP qep, int indent){</p>

<pre><code>int i,inc = 0;
str s;
if( qep-&gt;p){
    for(i=0;i&lt;indent; i++) mnstr_printf(f," ");
    s= instruction2str(qep-&gt;mb, 0,qep-&gt;p, LIST_MAL_STMT | LIST_MAPI);
    mnstr_printf(f,"%s\n",s);
    GDKfree(s);
    inc = 4;
}
for(i=0; i&lt; qep-&gt;climit; i++)
if( qep-&gt;children[i])
    QEPdump(f,qep-&gt;children[i], indent+ inc);
</code></pre>

<p>}</p>

<p>int
OPTdumpQEPImplementation(Client cntxt, MalBlkPtr mb, MalStkPtr stk, InstrPtr p){</p>

<pre><code>QEP qep;
(void) cntxt;
(void) stk;
(void) p;

qep= QEPbuilt(mb);
QEPdump(cntxt-&gt;fdout,qep,0);
return 1;
</code></pre>

<p>}
{% endcodeblock %}</p>

<blockquote><p><p><strong>6.范围传播 </strong></p>
<p>几乎所有的查询对表中的几个段有兴趣。如果用视图表示，查询计划经常含有对同一个列的选择。它们可能也修补了从碎片标准来的参数。 PUSHRANGES优化器的目的是最小化对表的范围的扫描。除非指令被移出计划。</p>
{% codeblock  lang:c %}
b := bat.new(:oid,:int);
s1:= algebra.select(b,1,100);
s2:= algebra.select(s1,5,95);
s3:= algebra.select(s2,50,nil);
s4:= algebra.select(s3,nil,75);
optimizer.pushranges();
{% endcodeblock %}
<p>这么长的序列可以被压缩成一条：</p>
{% codeblock  lang:c %}
b := bat.new(:oid,:int);
s1:= algebra.select(b,50,75);
{% endcodeblock %}
<p>从同一源码对两个范围的选择的并集可能是一个目标：</p>
{% codeblock  lang:c %}
t1:= algebra.select(b,1,10);
t2:= algebra.select(b,0,5);
t3:= algebra.union(t1,t2);
{% endcodeblock %}
<p>会变为：</p>
{% codeblock  lang:c %}
t3:= algebra.select(0,10);
{% endcodeblock %}
{% codeblock MonetDB范围传播的优化代码实现 lang:c %}
int OPTpushrangesImplementation(Client cntxt, MalBlkPtr mb, MalStkPtr stk, InstrPtr pci)
{</p>

<pre><code>int i,j, limit,actions=0;
InstrPtr p, *old;
int x,y,z;
Range range;
</code></pre></blockquote>

<pre><code>if( mb-&gt;errors) 
    return 0;
range= (Range) GDKzalloc(mb-&gt;vtop * sizeof(RangeRec));
if (range == NULL)
    return 0;
OPTDEBUGpushranges
    mnstr_printf(cntxt-&gt;fdout,"#Range select optimizer started\n");
(void) stk;
(void) pci;

limit = mb-&gt;stop;
old = mb-&gt;stmt;
/* In phase I we collect information about constants*/
for (i = 0; i &lt; limit; i++) {
    p = old[i];
    if( p-&gt;barrier) 
        break; /* end of optimizer */
    for(j=p-&gt;retc; j&lt; p-&gt;argc; j++)
        range[getArg(p,j)].used++;
    for(j=0; j&lt;p-&gt;retc; j++){
        range[getArg(p,j)].lastupdate= i;
        if( range[getArg(p,j)].lastrange == 0)
            range[getArg(p,j)].lastrange= i;
    } if( getModuleId(p)== algebraRef &amp;&amp; 
        ( getFunctionId(p)== selectRef || getFunctionId(p)== uselectRef) ){
        /*
         * The operation X:= algebra.select(Y,L,H,Li,Hi) is analysed.
         * First, we attempt to propagate the range known for Y onto the
         * requested range of X. This may lead to smaller range of
         * even the conclusion that X is necessarily empty.
         * Of course, only under the condition that Y has not been changed by a
         * side-effect since it was bound to X.
         */
        x= getArg(p,1);
        y= getArg(p,2);
        if( range[x].lcst &amp;&amp; isVarConstant(mb,y) ){
            /* merge lowerbound */
            if( ATOMcmp( getVarGDKType(mb,y), 
                    VALptr( &amp;getVarConstant(mb,range[x].lcst)), 
                    VALptr( &amp;getVarConstant(mb,y)) ) &gt; 0){
                getArg(p,2)= range[x].lcst;
                z= range[x].srcvar;
                if( getArg(p,1) == x &amp;&amp; 
                    range[z].lastupdate == range[z].lastrange){
                    getArg(p,1) = z;
                    actions++;
                }
            }
            y= getArg(p,3);
            /* merge higherbound */
            if( ATOMcmp( getVarGDKType(mb,y), 
                    VALptr( &amp;getVarConstant(mb,range[x].hcst)), 
                    VALptr( &amp;getVarConstant(mb,y)) ) &lt; 0 ||
                ATOMcmp( getVarGDKType(mb,y),
                    VALptr( &amp;getVarConstant(mb,y)),
                     ATOMnilptr(getVarType(mb,y)) ) == 0){
                getArg(p,3)= range[x].hcst;
                z= range[x].srcvar;
                if( getArg(p,1) == x &amp;&amp; range[z].lastupdate == range[z].lastrange){
                    getArg(p,1) = z;
                    actions++;
                }
            }
        }
        /*
         * The second step is to assign the result of this exercise to the
         * result variable.
         */
        x= getArg(p,0);
        if( isVarConstant(mb, getArg(p,2)) ){
            range[x].lcst = getArg(p,2);
            range[x].srcvar= getArg(p,1);
            range[x].lastupdate= range[x].lastrange = i;
        }
        if( isVarConstant(mb, getArg(p,3)) ){
            range[x].hcst = getArg(p,3);
            range[x].srcvar= getArg(p,1);
            range[x].lastupdate= range[x].lastrange = i;
        }
        /*
         * If both range bounds are constant, we can also detect empty results.
         * It is empty if L&gt; H or when L=H and the bounds are !(true,true).
         */
        x= getArg(p,2);
        y= getArg(p,3);
        if( isVarConstant(mb, x)  &amp;&amp;
            isVarConstant(mb, y)  ){
            z =ATOMcmp( getVarGDKType(mb,y),
                    VALptr( &amp;getVarConstant(mb,x)),
                    VALptr( &amp;getVarConstant(mb,y)));
            x=  p-&gt;argc &gt; 4;
            x= x &amp;&amp; isVarConstant(mb,getArg(p,4));
            x= x &amp;&amp; isVarConstant(mb,getArg(p,5));
            x= x &amp;&amp; getVarConstant(mb,getArg(p,4)).val.btval;
            x= x &amp;&amp; getVarConstant(mb,getArg(p,5)).val.btval;
            if( z &gt; 0 || (z==0 &amp;&amp; p-&gt;argc&gt;4 &amp;&amp; !x)) {
                int var = getArg(p, 0);
                wrd zero = 0;
                ValRecord v, *vp;

                vp = VALset(&amp;v, TYPE_wrd, &amp;zero);
                varSetProp(mb, var, rowsProp, op_eq, vp);
                /* create an empty replacement */
                x = getArgType(mb, p, 1);
                p-&gt;argc=1;
                getModuleId(p)= batRef;
                getFunctionId(p)= newRef;
                p= pushArgument(mb,p, newTypeVariable(mb, getHeadType(x)));
                (void) pushArgument(mb,p, newTypeVariable(mb, getTailType(x)));
                actions++;
            }
        }
    }
}
OPTDEBUGpushranges
    for(j=0; j&lt; mb-&gt;vtop; j++)
    if( range[j].used )
        printRange(cntxt, mb,range,j);
/*
 * Phase II, if we succeeded in pushing constants around and
 * changing instructions, we might as well try once more to perform
 * aliasRemoval, constantExpression, and pushranges.
 */
GDKfree(range);
return actions;
</code></pre>

<p>{% endcodeblock %}</p>

<blockquote><p><p><strong>7.循环再生器</strong></p>
<p>在现有的数据库系统中查询优化和处理经常仍集中在各自的查询。查询分开地被分析和和内核赛跑不管并行或之前的调用提供的机遇。这种方法远离最优和两个方向被发现可以改善：物理化视图和（部分）结果集重使用。物理化视图从查询日志中继承。它们代表公共的子查询，其物理化改善接下来查询时间。重用部分结果被用于放大或导航应用处于危急关头的情况。循环再生优化器和模块扩展这with a middle out approach.它们利用MonetDB的materialize-all-intermediate方法来决定保留它们只要被认为有利。</p>
<p>采用的方法是在MAL程序中使用recycler优化器调用标记指令，以至它们的结果被保留在一个全局的再生寄宿于MAL解析器的缓冲。指令受Recycler管制如果至少它其中一个参数是BAT和其他不是常数或者变量，且在Recycler已知。在运行的时候，在没有代价下，Recycler被MAL解析器最里层的循环调用去检查一个更新的会被保留的结果。否则，它计算指令和调用policy functions去决定是否这值得保留。</p>
<p>Recycler有几个policy控制操作在具体的设置下实验它的效果。retain policy控制什么时候保留结果，reuse policy照看具体复制的指令或者使用语义知识在MAL指令去探测潜在的使用（例如，重用select 结果）。最后，cache policy照管中间结果pool的存储空间。具体的细节在重用模块描述：</p>
{% codeblock MonetDB Recycler代码实现 lang:c %}
/<em>* The variables are all checked for being eligible as a variable
 * subject to recycling control. A variable may only be assigned
 * a value once. The target function is a sql.bind(-,-,-,0) or all arguments
 * are already recycle enabled or constant.
 *
 * The arguments of a function call cannot be recycled.
 * They change with each call. This does not mean
 * that the instructions using them can not be a
 * target of recycling.
 *
 * Just looking at a target result kept is not good enough.
 * You have to sure that the arguments are also the same.
 * This rules out function arguments.
 *
 * The recycler is targeted towards a read-only database.
 * The best effect is obtained for a single-user mode (sql_debug=32 )
 * when the delta-bats are not processed which allows longer instruction
 * chains to be recycled.
 * Update statements are not recycled. They trigger cleaning of
 * the recycle cache at the end of the query. Only intermediates
 * derived from the updated columns are invalidated.
 * Separate update instructions in queries, such as bat.append implementing 'OR',
 * are monitored and also trigger cleaning the cache.</em>/</p>

<h1>include "monetdb_config.h"</h1>

<h1>include "opt_recycler.h"</h1>

<h1>include "mal_instruction.h"</h1></blockquote>

<p>static lng recycleSeq = 0;      /<em> should become part of MAL block basics </em>/
static bte baseTableMode = 0;   /<em> only recycle base tables </em>/
int OPTrecyclerImplementation(Client cntxt, MalBlkPtr mb, MalStkPtr stk, InstrPtr p)
{</p>

<pre><code>int i, j, cnt, tp, c, actions = 0, marks = 0, delta = 0;
Lifespan span;
InstrPtr *old, q;
int limit, updstmt = 0;
char *recycled;
short app_sc = -1, in = 0;
ValRecord cst;

(void) cntxt;
(void) stk;

limit = mb-&gt;stop;
old = mb-&gt;stmt;

for (i = 1; i &lt; limit; i++) {
    p = old[i];
    if (getModuleId(p) == sqlRef &amp;&amp;
            (getFunctionId(p) == affectedRowsRef ||
             getFunctionId(p) == exportOperationRef ||
             getFunctionId(p) == appendRef ||
             getFunctionId(p) == updateRef ||
             getFunctionId(p) == deleteRef))
        updstmt = 1;
}

span = setLifespan(mb);
if (span == NULL)
    return 0;

/* watch out, newly created instructions may introduce new variables */
recycled = GDKzalloc(sizeof(char) * mb-&gt;vtop * 2);
if (recycled == NULL)
    return 0;
if (newMalBlkStmt(mb, mb-&gt;ssize) &lt; 0) {
    GDKfree(recycled);
    return 0;
}
pushInstruction(mb, old[0]);
mb-&gt;recid = recycleSeq++;

/* create a handle for recycler */
(void) newFcnCall(mb, "recycle", "prelude");
in = 1;
for (i = 1; i &lt; limit; i++) {
    p = old[i];
    if (hasSideEffects(p, TRUE) || isUpdateInstruction(p) || isUnsafeFunction(p)) {
        if (getModuleId(p) == recycleRef) { /*don't inline recycle instr. */
            freeInstruction(p);
            continue;
        }
        pushInstruction(mb, p);
        /*  update instructions are not recycled but monitored*/
        if (isUpdateInstruction(p)) {
            if (getModuleId(p) == batRef &amp;&amp;
                (getArgType(mb, p, 1) == TYPE_bat
                 || isaBatType(getArgType(mb, p, 1)))) {
                recycled[getArg(p, 1)] = 0;
                q = newFcnCall(mb, "recycle", "reset");
                pushArgument(mb, q, getArg(p, 1));
                actions++;
            }
            if (getModuleId(p) == sqlRef) {
                if (getFunctionId(p) == appendRef) {
                    if (app_sc &gt;= 0)
                        continue;
                    else
                        app_sc = getArg(p, 2);
                }
                VALset(&amp;cst, TYPE_int, &amp;delta);
                c = defConstant(mb, TYPE_int, &amp;cst);
                q = newFcnCall(mb, "recycle", "reset");
                pushArgument(mb, q, c);
                pushArgument(mb, q, getArg(p, 2));
                pushArgument(mb, q, getArg(p, 3));
                if (getFunctionId(p) == updateRef)
                    pushArgument(mb, q, getArg(p, 4));
                actions++;
            }
        }
        /* take care of SQL catalog update instructions */
        if (getModuleId(p) == sqlRef &amp;&amp; getFunctionId(p) == catalogRef) {
            tp = *(int *) getVarValue(mb, getArg(p, 1));
            if (tp == 22 || tp == 25) {
                delta = 2;
                VALset(&amp;cst, TYPE_int, &amp;delta);
                c = defConstant(mb, TYPE_int, &amp;cst);
                q = newFcnCall(mb, "recycle", "reset");
                pushArgument(mb, q, c);
                pushArgument(mb, q, getArg(p, 2));
                if (tp == 25)
                    pushArgument(mb, q, getArg(p, 3));
                actions++;
            }
        }
        continue;
    }
    if (p-&gt;token == ENDsymbol || p-&gt;barrier == RETURNsymbol) {
        if (in) {
            /*
            if (updstmt &amp;&amp; app_sc &gt;= 0) {
                q = newFcnCall(mb, "recycle", "reset");
                pushArgument(mb, q, app_sc);
                pushArgument(mb, q, app_tbl);
            }
             */
            (void) newFcnCall(mb, "recycle", "epilogue");
            in = 0;
        }
        pushInstruction(mb, p);
        continue;
    }

    if (p-&gt;barrier &amp;&amp; p-&gt;token != CMDcall) {
        /* never save a barrier unless it is a command and side-effect free */
        pushInstruction(mb, p);
        continue;
    }

    /* don't change instructions in update statements */
    if (updstmt) {
        pushInstruction(mb, p);
        continue;
    }

    /* skip simple assignments */
    if (p-&gt;token == ASSIGNsymbol) {
        pushInstruction(mb, p);
        continue;
    }

    if (getModuleId(p) == octopusRef &amp;&amp;
        (getFunctionId(p) == bindRef || getFunctionId(p) == bindidxRef)) {
        recycled[getArg(p, 0)] = 1;
        p-&gt;recycle = recycleMaxInterest;
        marks++;
    }
    /* During base table recycling skip marking instructions other than octopus.bind */
    if (baseTableMode) {
        pushInstruction(mb, p);
        continue;
    }

    /* general rule: all arguments are constants or recycled,
       ignore C pointer arguments from mvc */
    cnt = 0;
    for (j = p-&gt;retc; j &lt; p-&gt;argc; j++)
        if (recycled[getArg(p, j)] || isVarConstant(mb, getArg(p, j))
                || ignoreVar(mb, getArg(p, j)))
            cnt++;
    if (cnt == p-&gt;argc - p-&gt;retc) {
        OPTDEBUGrecycle {
            mnstr_printf(cntxt-&gt;fdout, "#recycle instruction\n");
            printInstruction(cntxt-&gt;fdout, mb, 0, p, LIST_MAL_ALL);
        }
        marks++;
        p-&gt;recycle = recycleMaxInterest; /* this instruction is to be monitored */
        for (j = 0; j &lt; p-&gt;retc; j++)
            if (getLastUpdate(span, getArg(p, j)) == i)
                recycled[getArg(p, j)] = 1;
    }
    /*
     * The expected gain is largest if we can re-use selections
     * on the base tables in SQL. These, however, are marked as
     * uselect() calls, which only produce the oid head.
     * For cheap types we preselect using select() and re-map uselect() back
     * over this temporary.
     * For the time being for all possible selects encountered
     * are marked for re-use.
     */
    /* take care of semantic driven recyling */
    /* for selections check the bat argument only
       the range is often template parameter*/
    if ((getFunctionId(p) == selectRef ||
                getFunctionId(p) == antiuselectRef ||
                getFunctionId(p) == likeselectRef ||
                getFunctionId(p) == likeRef ||
                getFunctionId(p) == thetaselectRef) &amp;&amp;
            recycled[getArg(p, 1)])
    {
        p-&gt;recycle = recycleMaxInterest;
        marks++;
        if (getLastUpdate(span, getArg(p, 0)) == i)
            recycled[getArg(p, 0)] = 1;
    }
    if ((getFunctionId(p) == uselectRef || getFunctionId(p) == thetauselectRef)
            &amp;&amp; recycled[getArg(p, 1)])
    {
        if (!ATOMvarsized(getGDKType(getArgType(mb, p, 2)))) {
            q = copyInstruction(p);
            getArg(q, 0) = newTmpVariable(mb, TYPE_any);
            if (getFunctionId(p) == uselectRef)
                setFunctionId(q, selectRef);
            else
                setFunctionId(q, thetaselectRef);
            q-&gt;recycle = recycleMaxInterest;
            marks++;
            recycled[getArg(q, 0)] = 1;
            pushInstruction(mb, q);
            getArg(p, 1) = getArg(q, 0);
            setFunctionId(p, projectRef);
            p-&gt;argc = 2;
        }
        p-&gt;recycle = recycleMaxInterest;
        marks++;
        if (getLastUpdate(span, getArg(p, 0)) == i)
            recycled[getArg(p, 0)] = 1;
    }

    if (getModuleId(p) == pcreRef) {
        if ((getFunctionId(p) == selectRef &amp;&amp; recycled[getArg(p, 2)]) ||
            (getFunctionId(p) == uselectRef &amp;&amp; recycled[getArg(p, 2)])) {
            p-&gt;recycle = recycleMaxInterest;
            marks++;
            if (getLastUpdate(span, getArg(p, 0)) == i)
                recycled[getArg(p, 0)] = 1;
        } else if (getFunctionId(p) == likeuselectRef &amp;&amp; recycled[getArg(p, 1)]) {
            q = copyInstruction(p);
            getArg(q, 0) = newTmpVariable(mb, TYPE_any);
            setFunctionId(q, likeselectRef);
            q-&gt;recycle = recycleMaxInterest;
            recycled[getArg(q, 0)] = 1;
            pushInstruction(mb, q);
            getArg(p, 1) = getArg(q, 0);
            setFunctionId(p, projectRef);
            setModuleId(p, algebraRef);
            p-&gt;argc = 2;
            p-&gt;recycle = recycleMaxInterest;
            marks += 2;
            if (getLastUpdate(span, getArg(p, 0)) == i)
                recycled[getArg(p, 0)] = 1;
        }
    }

    /*
     * The sql.bind instructions should be handled carefully
     * The delete and update BATs should not be recycled,
     * because they may lead to view dependencies that later interferes
     * with the transaction commits.
     */
    /* enable recycling of delta-bats
    if (getModuleId(p) == sqlRef &amp;&amp;
            (((getFunctionId(p) == bindRef || getFunctionId(p) == putName("bind_idxbat", 11)) &amp;&amp;
              getVarConstant(mb, getArg(p, 5)).val.ival != 0) ||
             getFunctionId(p) == binddbatRef)) {
        recycled[getArg(p, 0)] = 0;
        p-&gt;recycle = REC_NO_INTEREST;
    }
    */
</code></pre>

<p>/<em>
 * The sql.bind instructions should be handled carefully
 * The delete and update BATs should not be recycled,
 * because they may lead to view dependencies that later interferes
 * with the transaction commits.
 </em>/
/* enable recycling of delta-bats</p>

<pre><code>    if (getModuleId(p)== sqlRef &amp;&amp; 
        (((getFunctionId(p)==bindRef || getFunctionId(p) == putName("bind_idxbat",11)) &amp;&amp; 
            getVarConstant(mb, getArg(p,5)).val.ival != 0) ||
            getFunctionId(p)== binddbatRef) ) {
            recycled[getArg(p,0)]=0;
            p-&gt;recycle = REC_NO_INTEREST; 
        }
</code></pre>

<p>*/</p>

<pre><code>    pushInstruction(mb, p);
}
GDKfree(span);
GDKfree(old);
GDKfree(recycled);
mb-&gt;recycle = marks &gt; 0;
return actions + marks;
</code></pre>

<p>{% endcodeblock %}</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MonetDB 优化器]]></title>
    <link href="http://coolbrain.github.com/blog/2013/04/24/monetdb-optimizers/"/>
    <updated>2013-04-24T20:02:00+08:00</updated>
    <id>http://coolbrain.github.com/blog/2013/04/24/monetdb-optimizers</id>
    <content type="html"><![CDATA[<blockquote><p><p><strong>MonetDB 汇编语言优化器</strong></p>
<p>设计MonetDB中间语言的首要理由是能对数据库查询有一个高层次的描述，且这种语言容易被front-end编译器产生，容易编码，优化和解析。</p>
<!-- more -->
<p>一个有效的优化器需要几种机制保证。它可以执行对代码碎片的标志性评估和收集结果来帮助进一步的抉择。原型情况就是一个优化器估计选择操作结果的大小。另外主要的问题是可以产生和发掘替代评估计划的空间。这种发掘可以发生在前端，也可以在运行的时候对查询碎片。</p>
<p><strong>优化器的基础</strong></p>
<p>1.生命周期的分析</p>
<p>优化器为了做一个抉择可能对代码块的特性可能有兴趣。在代码块中变量都有生命周期，用属性beginLifespan，endLifespan来表示。beginLifespan表示指令在哪里得到其第一个值，endLifespan表示最后指令在哪里被使用作为操作数或目标。如果然而，最后的使用在BARRIER块里，我们不能确定它的生命状态的结束，因为代码块redo可能模糊地使用它。对于这些情况我们关联endLifespan到跳出代码块。</p>
<p>在许多的情况，我们需要决定是否生命周期干扰了一个预先准备好的优化决定。在优化器的开始序列中，生命周期被计算一次。它会被维持去反映最准确的情况当优化基础代码时。特别是，这意味着任何的 move/remove/addition MAL指令调用不是为了重现计算就是为了进一步的传播。不清楚什么会是最好的策略。暂时我们只是重新计算。</p>
<p>在点pc指令中提到里所有的参数都会在指令qc见到且不会同时更新。把变量可能在代码块内声明都考虑进来。这可能使用BARRIER/CATCH 和 EXIT对计算。对于每一个MAL函数安全的属性相对容易决定。这种调用是为了访问MAL函数块和监视签名的参数。</p>
<p>任何的指令可能阻碍公共子表达式的识别。他充分地阻碍一个其参数列表与目标指令有非空的交集的不安全的函数。为了说明，考虑序列：</p>
{% codeblock  lang:c %}
 L1 := f(A, B, C);
  ...
 G1 := g(D, E, F);
  ...
 l2 := f(A, B, C);
  ...
 L2 := h()
{% endcodeblock %}
<p>指令G1：=g(D, E, F) 阻塞如过G1 是｛A,B，C｝的别名。换言之，函数g()可能不安全和｛D，E，F｝和｛A,B，C｝有非空的交集。一个别名在以后的使用只能是只读。</p>
<p>MonetDB的执行优化前，设定生命周期的代码。</p>
{% codeblock 设置变量的生命周期setLifespan lang:c %}
Lifespan setLifespan(MalBlkPtr mb)
{</p>

<pre><code>int pc, k, depth=0, prop;
InstrPtr p;
int *blk;
Lifespan span= newLifespan(mb);
</code></pre></blockquote>

<pre><code>memset((char*) span,0, sizeof(LifespanRecord)* mb-&gt;vtop);
prop = PropertyIndex("transparent");

blk= (int *) GDKzalloc(sizeof(int)*mb-&gt;vtop);

for (pc = 0; pc &lt; mb-&gt;stop; pc++) {
    p = getInstrPtr(mb, pc);
    if( p-&gt;token == NOOPsymbol)
        continue;

    if( blockStart(p) &amp;&amp; varGetProp(mb, getArg(p,0), prop) == NULL)
        depth++;

    for (k = 0; k &lt; p-&gt;argc; k++) {
        int v = getArg(p,k);

        if (span[v].beginLifespan == 0 ){
            span[v].beginLifespan = pc;
            blk[v]= depth;
        }
        if (k &lt; p-&gt;retc )
            span[v].lastUpdate= pc;
        if ( blk[v] == depth )
            span[v].endLifespan = pc;

        if ( k &gt;= p-&gt;retc &amp;&amp; blk[v] &lt; depth )
            span[v].endLifespan = -1;   /* declared in outer scope*/
    }
    /*
     * @-
     * At a block exit we can finalize all variables defined within that block.
     * This does not hold for dataflow blocks. They merely direct the execution
     * thread, not the syntactic scope.
     */
    if( blockExit(p) ){
        for (k = 0; k &lt; mb-&gt;vtop; k++)
        if ( span[k].endLifespan == -1)
            span[k].endLifespan = pc;
        else
        if ( span[k].endLifespan == 0 &amp;&amp; blk[k]==depth)
            span[k].endLifespan = pc;
        if (varGetProp(mb, getArg(p,0), prop) == NULL )
            depth--;
    }
}
for (k = 0; k &lt; mb-&gt;vtop; k++)
if ( span[k].endLifespan == 0 )
    span[k].endLifespan = pc-2;/* generate them before the end */
GDKfree(blk);
return span;
</code></pre>

<p>}
{% endcodeblock %}</p>

<blockquote><p><p>2.流分析 </p>
<p>在许多优化规则里，语句间的数据流依赖尤其重要。MAL语言编码一个多源，多节点的数据流网络。优化器特别提取部分的工作流和使用语言的属性去枚举语义相等的解决方案，在给定的代价模型这出现导致更好的性能。流图在许多优化步骤里面扮演着重要的角色。什么是原始的和什么存储结构是最足够的是不清楚的。暂时我们引入必要的操作和对程序直接的评估。</p>
<p>对于每个变量我们应该确定他稳定的范围。在流图中的终点描述为不会产生永久数据的dead-code。当你知道这没有影响时，可以把它去掉。Side-effect自由评估应该在前端被知的属性。暂时，我们假设对于系统所有操作都是已知的。属性“不安全”是保留去识别这靠不住的情况。特别的是，一个bun-insert操作是不安全的，因为它改变了其中一个参数。</p>
<p><strong>MonetDB优化器详解：</strong></p>
<p>1.累加器评估:</p>
<p>批量的算术运算相当昂贵，因为对于每个表达式new BATs被创建。这内存饥饿被减少通过探测累加处理的机会，如，一个（临时）的变量被重写。如</p>
{% codeblock 考虑下列程序片段： lang:c %}
 t3:=batcalc.<em>(64,t2);
 t4:=batcalc,+(t1,t3);
 optimizer.accumulators();
{% endcodeblock %}
<p>如果变量t2是临时变量且不会在以后的程序块用到，我们可以重用它的存储空间和在剩余的代码中传播其别名。</p>
{% codeblock  lang:c %}
 batcalc.</em>(t2,64,t2);
 t4:=batcalc.+(t2,t1,t2);
{% endcodeblock %}
<p>这实现是直接的。它刚刚只是处理了在BATCALC可用的算术操作。这集合会慢慢地扩展的。关键的决定是去决定是否我们可以重写其中一个参数。在编译的时候，这是很难去检测的，如参数可能是绑定操作或代表一个通过永久BAT表示的视图的结果。因此，编译器注入调用ALGEBRA.REUSE()通过拷贝避免重写永久的BATs。</p>
{% codeblock MonetDB 累加器优化器代码： lang:c %}
int OPTaccumulatorsImplementation(Client cntxt, MalBlkPtr mb, MalStkPtr stk, InstrPtr pci)
{</p>

<pre><code>int i, limit,slimit;
InstrPtr p,q;
Module scope = cntxt-&gt;nspace;
int actions = 0;
InstrPtr *old;
Lifespan span;
</code></pre></blockquote>

<pre><code>(void) pci;
(void) stk;     /* to fool compilers */
span = setLifespan(mb);
if( span == NULL)
    return 0;
old= mb-&gt;stmt;
limit= mb-&gt;stop;
slimit= mb-&gt;ssize;
if ( newMalBlkStmt(mb,mb-&gt;stop) &lt; 0)
    return 0;
for (i = 0; i &lt; limit; i++) {
    p = old[i];

    if( getModuleId(p) != batcalcRef ) {
        pushInstruction(mb,p);
        continue;
    }
    OPTDEBUGaccumulators
        printInstruction(cntxt-&gt;fdout, mb, 0, p, LIST_MAL_ALL);
    if (p-&gt;retc==1 &amp;&amp; p-&gt;argc == 2) {
        /* unary operation, avoid clash with binary */
        pushInstruction(mb,p);
        continue;
    }
    if( getLastUpdate(span,getArg(p,0)) != i ) {
        /* only consider the last update to this variable */
        pushInstruction(mb,p);
        continue;
    }

    if (p-&gt;retc==1  &amp;&amp; p-&gt;argc == 3 &amp;&amp; isaBatType(getArgType(mb,p,0))) {
        int b1 =getEndLifespan(span,getArg(p,1))&lt;=i &amp;&amp; getArgType(mb,p,1) == getArgType(mb,p,0);
        int b2 =getEndLifespan(span,getArg(p,2))&lt;=i &amp;&amp; getArgType(mb,p,2) == getArgType(mb,p,0) ;
        if ( b1 == 0 &amp;&amp; b2 == 0){
            pushInstruction(mb,p);
            continue;
        }
        /* binary/unary operation, check arguments for being candidates */
        q= copyInstruction(p);
        p= pushBit(mb,p, b1);
        p= pushBit(mb,p, b2);

        typeChecker(cntxt-&gt;fdout, scope, mb, p, TRUE);
        if (mb-&gt;errors || p-&gt;typechk == TYPE_UNKNOWN) {
            OPTDEBUGaccumulators{
                mnstr_printf(cntxt-&gt;fdout,"# Failed typecheck");
                printInstruction(cntxt-&gt;fdout, mb, 0, p, LIST_MAL_ALL);
            }
            /* reset instruction error buffer */
            cntxt-&gt;errbuf[0]=0;
            mb-&gt;errors = 0;
            freeInstruction(p);
            p=q; /* restore */
        } else  {
            OPTDEBUGaccumulators{
                mnstr_printf(cntxt-&gt;fdout, "#Found accumulation candidate ");
                mnstr_printf(cntxt-&gt;fdout, "%d: %d(%d)\n", i, getArg(p,0),getArg(p,2));
                printInstruction(cntxt-&gt;fdout, mb, 0, p, LIST_MAL_ALL);
            }
            freeInstruction(q);
            actions++;  
        }
        OPTDEBUGaccumulators
            printInstruction(cntxt-&gt;fdout, mb, 0, p, LIST_MAL_ALL);
    }
    pushInstruction(mb,p);
} 
for (i = limit; i&lt;slimit; i++) 
    if(old[i])
        freeInstruction(old[i]);
GDKfree(old);
GDKfree(span);
DEBUGoptimizers
    mnstr_printf(cntxt-&gt;fdout,"#opt_accumulators:%d accumulations\n",actions);
return actions;
</code></pre>

<p>}</p>

<p>{% endcodeblock %}</p>

<blockquote><p><p>2.别名的去除：</p>
<p>任务 OPTIMIZER.ALIASREMOVAL()浏览程序寻找简单赋值语句，如，V:=W，它用W替代了所有的接下来的V，条件是V只是被赋值一次和W在剩下的代码中不会改变。特殊的例子在迭代的代码块中，如下所示：</p>
{% codeblock  lang:c %}</p>

<pre><code>     i:=0;
     b:="done";
</code></pre>

<p>barrier  go:=true;</p>

<pre><code>     c:= i+1;
     d:="step";
     v:=d;
     io.print(v);
     i:=c;
</code></pre>

<p>  redo go:=i lower than 2;
  exit go;</p>

<pre><code>     io.print(b);
     optimizer.aliasRemoval();
</code></pre>

<p>{% endcodeblock %}
<p>字符常量被传入到PRINT()任务，当初始的赋值i：= 0 需要保留。代码块变成：</p>
{% codeblock  lang:c %}</p>

<pre><code>     i:=0;
</code></pre>

<p>barrier  go:=true;</p>

<pre><code>     c:= i+1;
     io.print(step");
     i:=c;
</code></pre>

<p>  redo go:=i lower than 2;
  exit go;</p>

<pre><code>     io.print("done");
     optimizer.aliasRemoval();
</code></pre>

<p>{% endcodeblock %}
<p>下面是MonetDB别名去除优化的代码：</p>
{% codeblock  lang:c %}
int OPTaliasesImplementation(Client cntxt, MalBlkPtr mb, MalStkPtr stk, InstrPtr p)
{</p>

<pre><code>int i,k=1, limit, actions=0;
int *alias;
Lifespan span;
</code></pre></blockquote>

<pre><code>(void) stk;
(void) cntxt;
span= setLifespan(mb);
if( span == NULL)
    return 0;

alias= (int*) GDKmalloc(sizeof(int)* mb-&gt;vtop);
if (alias == NULL)
    return 0;
for(i=0; i&lt;mb-&gt;vtop; i++) alias[i]=i;

limit = mb-&gt;stop;
for (i = 1; i &lt; limit; i++){
    p= getInstrPtr(mb,i);
    mb-&gt;stmt[k++] = p;
    if (OPTisAlias(p)){
        if( getLastUpdate(span,getArg(p,0)) == i  &amp;&amp;
            getBeginLifespan(span,getArg(p,0)) == i  &amp;&amp;
            getLastUpdate(span,getArg(p,1)) &lt;= i ){
            alias[getArg(p,0)]= alias[getArg(p,1)];
            freeInstruction(p);
            actions++;
            k--;
        } else 
            OPTaliasRemap(p,alias);
    } else 
        OPTaliasRemap(p,alias);
}
for(i=k; i&lt;limit; i++)
    mb-&gt;stmt[i]= NULL;
mb-&gt;stop= k;
/*
 * @-
 * The second phase is constant alias replacement should be implemented.
 */
GDKfree(span);
GDKfree(alias);
DEBUGoptimizers
    mnstr_printf(cntxt-&gt;fdout,"#opt_aliases: %d removed\n",actions);
return actions;
</code></pre>

<p>{% endcodeblock %}</p>

<blockquote><p><p>3.代码工厂化 ：</p>
<p>在大部分真正的情况，查询在它们的参数有稍微的差别被重复地调用。这种情况通过保持近期查询计划的缓存可以被查询优化器捕捉。在MonetDB上下文这样的查询被表示为参数化的MAL程序。进一步优化缓存函数将查询计划分成两块可能你有帮助。一个区域有不依赖于给定参数的操作和另一区域包含查询的核心使用所有的信息。这样的程序可以被MAL工厂表示，是一个可重入的查询计划。一个工厂化改变代码的例子如下：</p>
{% codeblock  lang:c %}
function test(s:str):lng;</p>

<pre><code>b:= bat.new(:int,:str);
bat.insert(b,1,"hello");
z:= algebra.select(b,s,s);
i:= aggr.count(z);
return i;
</code></pre>

<p>end test;</p>

<pre><code>optimizer.factorize("user","test");
</code></pre>

<p>{% endcodeblock %}
<p>转变为下面的代码</p>
{% codeblock  lang:c %}
factory user.test(s:str):lng;</p>

<pre><code>b := bat.new(:int,:str);
bat.insert(b,1,"hello");
</code></pre>

<p>barrier always := true;</p>

<pre><code>z := algebra.select(b,s,s);
i := aggr.count(z);
yield i;
redo always;
</code></pre>

<p>exit always;
end test;
{% endcodeblock %}
<p>包含的工厂生成器是MAL工厂化的原型实现。被采用的方法是将程序分成两块和把其包装为MAL工厂。优化假设数据库表在工厂的生命时间中只访问一次不会改变。这样的变化应该被外面检测和接着是重启的工厂。一个重定义用户可以识别‘冻僵’的参数的模式会留给将来。因为查询会映射到人和可用的工厂去处理请求。暂时我们简单地重组计划的所有参数。工厂化的操作干扰OPTIMIZER.EXPRESSIONACCUMULATION() 因为这可能会重写参数。暂时，这在本地任务会被捕捉。</p>
{% codeblock MonetDB工厂化优化代码 lang:c %}
int OPTfactorizeImplementation(Client cntxt, MalBlkPtr mb, MalStkPtr stk, InstrPtr pci)
{</p>

<pre><code>int i, k,  v, noop = 0, se;
InstrPtr *mbnew;
InstrPtr p,sig;
int fk = 0, sk = 0, blk = 0, blkstart = 0;
int *varused, returnseen = 0, retvar=0;
InstrPtr *first, *second;
Lifespan span;
</code></pre></blockquote>

<pre><code>(void) cntxt;
(void) pci;
(void) stk;     /* to fool compilers */

span = setLifespan(mb);
if( span == NULL)
    return 0;

varused = GDKmalloc(mb-&gt;vtop * sizeof(int));
if ( varused == NULL) {
    GDKfree(span);
    return 0;
}
for (i = 0; i &lt; mb-&gt;vtop; i++)
    varused[i] = 0;

/* add parameters to use list */
sig = getInstrPtr(mb, 0);
for (i = 0; i &lt; sig-&gt;argc; i++)
    varused[i] = 1;

first = (InstrPtr *) GDKzalloc(mb-&gt;ssize * sizeof(InstrPtr));
if ( first == NULL){
    GDKfree(span);
    GDKfree(varused);
    return 0;
}
second = (InstrPtr *) GDKzalloc(mb-&gt;ssize * sizeof(InstrPtr));
if ( second == NULL){
    GDKfree(span);
    GDKfree(varused);
    GDKfree(first);
    return 0;
}

first[fk++] = getInstrPtr(mb, 0);   /* to become a factory */
for (i = 1; i &lt; mb-&gt;stop - 1; i++) {
    p = getInstrPtr(mb, i);
    se = 0;
    for (k = 0; k &lt; p-&gt;argc; k++)
        if (varused[p-&gt;argv[k]])
            se++;

    /* detect blocks they are moved to the second part */
    /* a more clever scheme can be designed though */
    if (p-&gt;barrier) {
        if (p-&gt;barrier == BARRIERsymbol || p-&gt;barrier == CATCHsymbol) {
            if (blkstart == 0)
                blkstart = i;
            blk++;
        } else if (p-&gt;barrier == EXITsymbol) {
            blk--;
            if (blk == 0)
                blkstart = 0;
        }
    }

    /* beware, none of the target variables may live
       before the cut point.  */
    for (k = 0; k &lt; p-&gt;retc; k++)
        if (getBeginLifespan(span, p-&gt;argv[k])&lt; i || !OPTallowed(p))
            se = 0;
    if (p-&gt;barrier == RETURNsymbol) {
        se = 1;
        p-&gt;barrier = YIELDsymbol;
        returnseen = 1;
        retvar= getArg(p,0);
    }

    if (se == 0 &amp;&amp; blk == 0)
        first[fk++] = p;
    else {
        if (blkstart) {
            /* copy old block stuff */
            for (k = blkstart; k &lt; i; k++)
                second[sk++] = first[k];
            fk = blkstart;
            blkstart = 0;
        }
        second[sk++] = p;
        for (k = 0; k &lt; p-&gt;retc; k++)
            varused[p-&gt;argv[k]] = 1;
    }
}
second[sk++] = getInstrPtr(mb, i);
/* detect need for factorization, assume so */
if (noop || sk == 0) {
    GDKfree(varused);
    GDKfree(first);
    GDKfree(second);
    GDKfree(span);
    /* remove the FToptimizer request */
    return 1;
}

first[0]-&gt;token = FACTORYsymbol;

mbnew = (InstrPtr *) GDKmalloc((mb-&gt;stop + 4) * sizeof(InstrPtr));
if ( mbnew == NULL) {
    GDKfree(span);
    GDKfree(varused);
    GDKfree(first);
    GDKfree(second);
    return 0;
}
GDKfree(mb-&gt;stmt);
mb-&gt;stmt = mbnew;

mb-&gt;stop = mb-&gt;stop + 4;

k = 0;
for (i = 0; i &lt; fk; i++)
    mb-&gt;stmt[k++] = first[i];

/* added control block */
v = newVariable(mb, GDKstrdup("always"), TYPE_bit);
p = newInstruction(NULL,ASSIGNsymbol);
p-&gt;barrier = BARRIERsymbol;
getArg(p,0) = v;
p= pushBit(mb,p,TRUE);
mb-&gt;stmt[k++] = p;

for (i = 0; i &lt; sk - 1; i++)
    mb-&gt;stmt[k++] = second[i];

/* finalize the factory */
if (returnseen == 0) {
    p= newInstruction(NULL,ASSIGNsymbol);
    p-&gt;barrier = YIELDsymbol;
    getArg(p,0)= getArg(sig,0);
    mb-&gt;stmt[k++] = p;
}
p = newInstruction(NULL,REDOsymbol);
p= pushReturn(mb, p, v);
mb-&gt;stmt[k++] = p;

p = newInstruction(NULL,EXITsymbol);
p= pushReturn(mb, p, v);
mb-&gt;stmt[k++] = p;

/* return a nil value */
if ( getVarType(mb,retvar) != TYPE_void){
    p = newInstruction(NULL,RETURNsymbol);
    getArg(p,0) = getArg(sig,0);
    pushArgument(mb,p, retvar);
    mb-&gt;stmt[k++] = p;
}
/* add END statement */
mb-&gt;stmt[k++] = second[i];

mb-&gt;stop = k;

GDKfree(varused);
GDKfree(first);
GDKfree(second);
GDKfree(span);
return 1;
</code></pre>

<p>}
{% endcodeblock %}</p>

<blockquote><p>4.删除强制转换：
<p>一个简单的优化器去除不需要的强制转换。它们可能来源于草率的代码生成器或函数调用决议决定。如 v:= calc.int(32);
成为一个简单地赋值，不需要函数调用。最主要的角色是一个编码一个优化算法的说明。</p>
{% codeblock MonetDB删除强制转换的代码 lang:c %}
static int coercionOptimizerStep(MalBlkPtr mb, int i, InstrPtr p)
{</p>

<pre><code>int t, k, a, b;
</code></pre></blockquote>

<pre><code>a = getArg(p, 0);
b = getArg(p, 1);
t = getVarType(mb, b);
if (getVarType(mb, a) != t)
    return 0;
if (strcmp(getFunctionId(p), ATOMname(t)) == 0) {
    removeInstruction(mb, p); /* dead code */
    for (; i &lt; mb-&gt;stop; i++) {
        p = getInstrPtr(mb, i);
        for (k = p-&gt;retc; k &lt; p-&gt;argc; k++)
            if (p-&gt;argv[k] == a)
                p-&gt;argv[k] = b;
    }
    return 1;
}
return 0;
</code></pre>

<p>}
int  OPTcoercionImplementation(Client cntxt,MalBlkPtr mb, MalStkPtr stk, InstrPtr pci)
{</p>

<pre><code>int i, k;
InstrPtr p;
int actions = 0;
str calcRef= putName("calc",4);

(void) cntxt;
(void) pci;
(void) stk;     /* to fool compilers */

for (i = 1; i &lt; mb-&gt;stop; i++) {
    p = getInstrPtr(mb, i);
    if (getModuleId(p) == NULL)
        continue;
    if (getModuleId(p)==calcRef &amp;&amp; p-&gt;argc == 2) {
        k= coercionOptimizerStep(mb, i, p);
        actions += k;
        if( k) i--;
    }
}
/*
 * This optimizer affects the flow, but not the type and declaration
 * structure. A cheaper optimizer is sufficient.
 */
DEBUGoptimizers
    mnstr_printf(cntxt-&gt;fdout,"#opt_coercion: %d coersions applied\n",actions);
return actions;
</code></pre>

<p>}
{% endcodeblock %}</p>

<blockquote><p><p>5.消除公共子表达式: </p>
<p>消除公共子表达只涉及对程序块的扫描去检测重复出现的语句。最在说明最关键的问题是保证在重复指令里涉及到的参数都是不变的。对OPTIMIZER.COMMONTERMS()分析是相当简陋的。带有可能有side-effects的参数的所有函数应该被标志为‘不安全’。在MAL块中它们的使用跳出涉及所有对象的数据流图(BATs,所有的东西保存在盒子里）。消除子表达优化器位于相同指令的后面。只要发现相同的它就会停止。在我们用前面的变量代替表达式之前，我们假设我们还没有通过一个非空的代码块</p>
{% codeblock  lang:c %}</p>

<pre><code>b:= bat.new(:int,:int);
c:= bat.new(:int,:int);
d:= algebra.select(b,0,100);
e:= algebra.select(b,0,100);
k1:= 24;
k2:= 27;
l:= k1+k2;
l2:= k1+k2;
l3:= l2+k1;
optimizer.commonTerms();
</code></pre>

<p>{% endcodeblock %}
<p>会被转换成代码块，开始的两个指令不是相同的，因为它们有side 影响</p>
{% codeblock  lang:c %}</p>

<pre><code>b := bat.new(:int,:int);
c := bat.new(:int,:int);
d := algebra.select(b,0,100
e := d;
l := calc.+(24,27);
l3 := calc.+(l,24);
</code></pre>

<p>{% endcodeblock %}
{% codeblock MonetDB 消除公共子表达式的代码段 lang:c %}
int  OPTcommonTermsImplementation(Client cntxt, MalBlkPtr mb, MalStkPtr stk, InstrPtr pci)
{</p>

<pre><code>int i, j, k, prop, candidate, barrier= 0, cnt;
InstrPtr p, q;
int actions = 0;
int limit, slimit;
int *alias;
InstrPtr *old;
int *list;  
/* link all final constant expressions in a list */
/* it will help to find duplicate sql.bind calls */
int cstlist=0;
int *vars;
</code></pre></blockquote>

<pre><code>(void) cntxt;
(void) stk;
(void) pci;
alias = (int*) GDKzalloc(sizeof(int) * mb-&gt;vtop);
list = (int*) GDKzalloc(sizeof(int) * mb-&gt;stop);
vars = (int*) GDKzalloc(sizeof(int) * mb-&gt;vtop);
if ( alias == NULL || list == NULL || vars == NULL){
    if(alias) GDKfree(alias);
    if(list) GDKfree(list);
    if(vars) GDKfree(vars);
    return 0;
}

old = mb-&gt;stmt;
limit = mb-&gt;stop;
slimit = mb-&gt;ssize;
if ( newMalBlkStmt(mb, mb-&gt;ssize) &lt; 0){
    GDKfree(alias);
    GDKfree(list);
    GDKfree(vars);
    return 0; 
}

for ( i = 0; i &lt; limit; i++) {
    p = old[i];

    for ( k = 0; k &lt; p-&gt;argc; k++)
    if ( alias[getArg(p,k)] )
        getArg(p,k) = alias[getArg(p,k)];

    /* Link the statement to the previous use, based on the last argument.*/
    if ( p-&gt;retc &lt; p-&gt;argc ) {
        candidate = vars[getArg(p,p-&gt;argc-1)];
        if ( isVarConstant(mb, getArg(p,p-&gt;argc-1)) ){
            /* all instructions with constant tail are linked */
            list[i] = cstlist;
            cstlist = i;
        } else
            list[i]= vars[ getArg(p,p-&gt;argc-1) ];
        vars[getArg(p,p-&gt;argc-1)] = i;
    } else candidate = 0;

    pushInstruction(mb,p);
    if (p-&gt;token == ENDsymbol){
        /* wrap up the remainder */
        for(i++; i&lt;limit; i++)
            if( old[i])
                pushInstruction(mb,old[i]);
        break;
    }
    /*
     * @-
     * Any non-empty barrier block signals the end of this optimizer,
     * the impact of the block can affect the common code.
     */
    barrier |= (p-&gt;barrier== BARRIERsymbol || p-&gt;barrier== CATCHsymbol) &amp;&amp; old[i+1]-&gt;barrier!=EXITsymbol;
    /*
     * @-
     * Also block further optimization when you have seen an assert().
     * This works particularly for SQL, because it is not easy to track
     * the BAT identifier aliases to look for updates. The sql.assert
     * at least tells us that an update is planned.
     * Like all optimizer decisions, it is safe to stop.
     */
    barrier |= getFunctionId(p) == assertRef;
    if (p-&gt;token == NOOPsymbol || p-&gt;token == ASSIGNsymbol || barrier /* || p-&gt;retc == p-&gt;argc */) {
</code></pre>

<h1>ifdef DEBUG_OPT_COMMONTERMS_MORE</h1>

<pre><code>            mnstr_printf(cntxt-&gt;fdout, "COMMON SKIPPED[%d] %d %d\n",i, barrier, p-&gt;retc == p-&gt;argc);
</code></pre>

<h1>endif</h1>

<pre><code>        continue;
    }

    /* from here we have a candidate to look for a match */
</code></pre>

<h1>ifdef DEBUG_OPT_COMMONTERMS_MORE</h1>

<pre><code>    mnstr_printf(cntxt-&gt;fdout,"#CANDIDATE[%d] ",i);
    printInstruction(cntxt-&gt;fdout, mb, 0, p, LIST_MAL_ALL);
</code></pre>

<h1>endif</h1>

<pre><code>    prop = hasSideEffects(p,TRUE) || isUpdateInstruction(p);
    j = isVarConstant(mb, getArg(p,p-&gt;argc-1))? cstlist: candidate;

    cnt = mb-&gt;stop / 128 &lt; 32? 32 : mb-&gt;stop/128;   /* limit search depth */
    if ( !prop)
    for (; cnt &gt; 0 &amp;&amp; j ; cnt--, j = list[j]) 
        if ( getFunctionId(q=getInstrPtr(mb,j)) == getFunctionId(p) &amp;&amp; getModuleId(q) == getModuleId(p)  ){
</code></pre>

<h1>ifdef DEBUG_OPT_COMMONTERMS_MORE</h1>

<pre><code>        mnstr_printf(cntxt-&gt;fdout,"#CANDIDATE %d, %d  %d %d ", i, j, 
            hasSameSignature(mb, p, q, p-&gt;retc), 
            hasSameArguments(mb, p, q));
            printInstruction(cntxt-&gt;fdout, mb, 0, q, LIST_MAL_ALL);
            mnstr_printf(cntxt-&gt;fdout," :%d %d %d=%d %d %d %d %d %d\n", 
                q-&gt;token != ASSIGNsymbol ,
                list[getArg(q,q-&gt;argc-1)],i,
                !hasCommonResults(p, q), 
                !hasSideEffects(q, TRUE),
                !isUpdateInstruction(q),
                isLinearFlow(q),
                isLinearFlow(p));
</code></pre>

<h1>endif</h1>

<pre><code>            /*
             * @-
             * Simple assignments are not replaced either. They should be
             * handled by the alias removal part. All arguments should
             * be assigned their value before instruction p.
             */
            if ( hasSameArguments(mb, p, q) &amp;&amp; 
                hasSameSignature(mb, p, q, p-&gt;retc) &amp;&amp; 
                !hasCommonResults(p, q) &amp;&amp; 
                !isUnsafeFunction(q) &amp;&amp; 
                isLinearFlow(q) 
               ) {
                    if (safetyBarrier(p, q) ){
</code></pre>

<h1>ifdef DEBUG_OPT_COMMONTERMS_MORE</h1>

<pre><code>                    mnstr_printf(cntxt-&gt;fdout,"#safetybarrier reached\n");
</code></pre>

<h1>endif</h1>

<pre><code>                    break;
                }
</code></pre>

<h1>ifdef DEBUG_OPT_COMMONTERMS_MORE</h1>

<pre><code>                    mnstr_printf(cntxt-&gt;fdout, "Found a common expression " "%d &lt;-&gt; %d\n", j, i);
                    printInstruction(cntxt-&gt;fdout, mb, 0, q, LIST_MAL_ALL);
</code></pre>

<h1>endif</h1>

<pre><code>                clrFunction(p);
                p-&gt;argc = p-&gt;retc;
                for (k = 0; k &lt; q-&gt;retc; k++){
                    alias[getArg(p,k)] = getArg(q,k);
                    p= pushArgument(mb,p, getArg(q,k));
                }
</code></pre>

<h1>ifdef DEBUG_OPT_COMMONTERMS_MORE</h1>

<pre><code>                mnstr_printf(cntxt-&gt;fdout, "COMMON MODIFIED EXPRESSION %d -&gt; %d\n",i,j);
                printInstruction(cntxt-&gt;fdout, mb, 0, p, LIST_MAL_ALL);
</code></pre>

<h1>endif</h1>

<pre><code>                actions++;
                break; /* end of search */
            }
        }
</code></pre>

<h1>ifdef DEBUG_OPT_COMMONTERMS_MORE</h1>

<pre><code>        else if ( hasSideEffects(q, TRUE) || isUpdateInstruction(p)){
            mnstr_printf(cntxt-&gt;fdout, "COMMON SKIPPED %d %d\n", hasSideEffects(q, TRUE) , isUpdateInstruction(p));
            printInstruction(cntxt-&gt;fdout, mb, 0, q, LIST_MAL_ALL);
        }
</code></pre>

<h1>endif</h1>

<pre><code>}
for(; i&lt;slimit; i++)
    if( old[i])
        freeInstruction(old[i]);
GDKfree(list);
GDKfree(vars);
GDKfree(old);
GDKfree(alias);
DEBUGoptimizers
    mnstr_printf(cntxt-&gt;fdout,"#opt_commonTerms: %d statements catched\n",actions);
</code></pre>

<h1>ifdef DEBUG_OPT_COMMONTERMS_MORE</h1>

<pre><code>    mnstr_printf(cntxt-&gt;fdout,"#opt_commonTerms: %d statements catched\n",actions);
</code></pre>

<h1>endif</h1>

<pre><code>return actions;
</code></pre>

<p>}
{% endcodeblock %}</p>

<blockquote><p><p>6.常量表达式评估：</p>
<p>由编译器产生只涉及常量的参数的表达式可以被评估一次。它特别是与经常被调用的函数相关。一次的查询不会从这额外的步骤得益。考虑下列的包含重复使用的常量参数的代码片段。</p>
{% codeblock  lang:c %}</p>

<pre><code>a:= 1+1;    io.print(a);
b:= 2;      io.print(b);
c:= 3*b;    io.print(c);
d:= calc.flt(c);    io.print(d);
e:= mmath.sin(d);   io.print(e);
optimizer.aliasRemoval();
optimizer.evaluate();
</code></pre>

<p>{% endcodeblock %}
<p>会被转换成代码块</p>
{% codeblock  lang:c %}</p>

<pre><code>io.print(2);
io.print(2);
io.print(6);
io.print(6);
io.print(-0.279415488);
</code></pre>

<p>/<em>同样的我们尝试基于常量捕捉barrier块</em>/
{% endcodeblock %}
{% codeblock MonetDB常量表达式优化 lang:c %}
int  OPTconstantsImplementation(Client cntxt, MalBlkPtr mb, MalStkPtr stk, InstrPtr p)
{</p>

<pre><code>int i,k=1, n=0, fnd=0, actions=0;
int *alias, *index;
VarPtr x,y, *cst;
</code></pre></blockquote>

<pre><code>OPTDEBUGconstants mnstr_printf(cntxt-&gt;fdout,"#OPT_CONSTANTS: MATCHING CONSTANTS ELEMENTS\n");

alias= (int*) GDKzalloc(sizeof(int) * mb-&gt;vtop);
cst= (VarPtr*) GDKzalloc(sizeof(VarPtr) * mb-&gt;vtop);
index= (int*) GDKzalloc(sizeof(int) * mb-&gt;vtop);

if ( alias == NULL || cst == NULL || index == NULL){
    if( alias) GDKfree(alias);
    if( cst) GDKfree(cst);
    if( index) GDKfree(index);
    return 0;
}

(void) stk;
(void) cntxt;

for (i=0; i&lt; mb-&gt;vtop; i++)
    alias[ i]= i;
for (i=0; i&lt; mb-&gt;vtop; i++)
    if ( isVarConstant(mb,i)  &amp;&amp; isVarFixed(mb,i) ){
        x= getVar(mb,i); 
        fnd = 0;
        if ( x-&gt;type &amp;&amp; x-&gt;value.vtype)
        for( k= n-1; k&gt;=0; k--){
            y= cst[k];
            if ( x-&gt;type == y-&gt;type &amp;&amp;
                 x-&gt;value.vtype == y-&gt;value.vtype &amp;&amp;
                ATOMcmp(x-&gt;value.vtype, VALptr(&amp;x-&gt;value), VALptr(&amp;y-&gt;value)) == 0){
                OPTDEBUGconstants {
                    mnstr_printf(cntxt-&gt;fdout,"#opt_constants: matching elements %s %d %d ", getVarName(mb,i), i,k);
                    ATOMprint(x-&gt;value.vtype,VALptr(&amp;x-&gt;value),cntxt-&gt;fdout);
                    mnstr_printf(cntxt-&gt;fdout,"\n");
                }
                /* re-use a constant */
                alias[i]= index[k];
                fnd=1;
                actions++;
                break;
            }
        }
        if ( fnd == 0){
            OPTDEBUGconstants mnstr_printf(cntxt-&gt;fdout,"swith elements %d %d\n", i,n);
            cst[n]= x;
            index[n]= i;
            n++;
        } 
    } 

for (i = 0; i &lt; mb-&gt;stop; i++){
    p= getInstrPtr(mb,i);
    for (k=0; k &lt; p-&gt;argc; k++)
        getArg(p,k) = alias[getArg(p,k)];
}
DEBUGoptimizers
    mnstr_printf(cntxt-&gt;fdout,"#opt_constants: %d constant duplicates removed\n", actions);
GDKfree(alias);
GDKfree(cst);
GDKfree(index);
return actions;
</code></pre>

<p>{% endcodeblock %}</p>

<blockquote><p><p>7.代价模型方法:</p>
<p>代价模型是许多优化决定的基础。代价参数经常是（中间的）结果的大小和反应的时间。换言之，它们是运行聚集，如，从模拟运行中得到的最大的内存使用和总共的运行时间。当前的实现包含一个框架和对自身以代价为基础的例子。OPTIMIZER.COSTMODEL（）以自己的方式在MAL程序中运行寻找关系运算和估计它们结果的大小。估计的大小被置后作为属性ROWS。</p>
{% codeblock  lang:c %}</p>

<pre><code>r{rows=100} := bat.new(:oid,:int);
s{rows=1000}:= bat.new(:oid,:int);
rs:= algebra.select(s,1,1);
rr:= bat.reverse(r);
j:= algebra.join(rs,rr);
optimizer.costModel();
</code></pre>

<p>{% endcodeblock %}
<p>该表指令的属性如下：</p>
{% codeblock  lang:c %}</p>

<pre><code>r{rows=100} := bat.new(:oid,:int);
s{rows=1000} := bat.new(:oid,:int);
rs{rows=501} := algebra.select(s,1,1);
rr{rows=100} := bat.reverse(r);
j{rows=100} := algebra.join(rs,rr);
</code></pre>

<p>{% endcodeblock %}
<p>代价估计在真正的数据分布上未用任何的统计。它依赖于由front-end或其它优化器提供的ROWS属性。它只是使用了一些启发式代价估计器。然而，它保证空的结果会被ROWS=0标记，如果估计是精确的，否则它假设至少一个结果行。这个属性使安全传递代价估计的结果到减少代码的EMPTYSET优化器成为可能。</p>
{% codeblock MonetDB代价估计实现代码  lang:c %}
 /<em>The cost will be used in many places to make decisions.
 * Access should be fast.
 * The SQL front-end also makes the BAT index available as the
 * property bid. This can be used to access the BAT and involve
 * more properties into the decision procedure.
 * Also make sure you don't re-use variables, because then the
 * row count becomes non-deterministic.</em>/
int OPTcostModelImplementation(Client cntxt, MalBlkPtr mb, MalStkPtr stk, InstrPtr pci)
{</p>

<pre><code>int i, actions = 1;
wrd k, c1, c2;
InstrPtr p;
str sortrevRef= putName("sortReverse",11);
str sortrevTailRef= putName("sortReverseTail",15);
str projectRef= putName("project",7);
</code></pre></blockquote>

<pre><code>(void) cntxt;
(void) stk;
(void) pci;

if (varGetProp(mb, getArg(mb-&gt;stmt[0], 0), inlineProp) != NULL)
    return 0;

for (i = 0; i &lt; mb-&gt;stop; i++) {
    p = getInstrPtr(mb, i);
    if (getModuleId(p)==algebraRef) {
        if (getFunctionId(p) == markTRef  ||
            getFunctionId(p) == markHRef  ||
            getFunctionId(p) == selectNotNilRef  ||
            getFunctionId(p) == sortRef  ||
            getFunctionId(p) == sortTailRef  ||
            getFunctionId(p) == sortrevRef  ||
            getFunctionId(p) == sortrevTailRef  ||
            getFunctionId(p) == projectRef  ){
            newRows(1,1,c1,0);
        } else if(getFunctionId(p) == unionRef ||
            getFunctionId(p) == kunionRef) {
            newRows(1,2,(c1+c2),0);
        } else if (getFunctionId(p)== kdifferenceRef) {
            newRows(1,2,(c1==0?0:c2==0?c1: c1 - c2 &lt; 0 ? 1 : c1 - c2+1),0);
        } else if (getFunctionId(p) == joinRef ||
            getFunctionId(p) == leftjoinRef ||
            getFunctionId(p) == leftjoinPathRef ) {
            /* assume 1-1 joins */
            newRows(1,2,(c1 &lt; c2 ? c1 : c2),0);
        } else if (getFunctionId(p) == semijoinRef ) {
            /* assume 1-1 semijoins */
            newRows(1,2,(c1 &lt; c2? c1 : c2),0);
        } else if (getFunctionId(p) == selectRef ||
            getFunctionId(p) == uselectRef ||
            getFunctionId(p) == thetaselectRef ||
            getFunctionId(p) == thetauselectRef) {
            newRows(1,1, (c1 &gt; 100 ? c1 / 2 +1: c1),0);
        } else if (getFunctionId(p) == crossRef) {
            newRows(1,2,((log((double) c1) + log((double) c2) &gt; log(INT_MAX) ? INT_MAX : c1 * c2 +1)),0);
        } else if (getFunctionId(p) == tuniqueRef ) {
            newRows(1,1,( c1 &lt; 50 ? c1 : c1 / 10+1),0);
        }
    } else if (getModuleId(p) == batcalcRef) {
        if( getFunctionId(p) == ifthenelseRef) {
            if( isaBatType(getArgType(mb,p,2) ) ) {
                newRows(2,2, c1,0);
            } else {
                newRows(3,3, c1,0);
            }
        } else if( isaBatType(getArgType(mb,p,1)) ){
                newRows(1,1, c1,0);
            } else {
                newRows(2, 2, c2,0);
            }
    } else if (getModuleId(p) == batstrRef) {
            newRows(1,1, c1,0);
    } else if (getModuleId(p) == batRef) {
        if (getFunctionId(p) == reverseRef ||
            getFunctionId(p) == setWriteModeRef  ||
            getFunctionId(p) == hashRef  ||
            getFunctionId(p) == mirrorRef) {
            newRows(1,1, c1,0);
        } else if (getFunctionId(p) == appendRef ||
               getFunctionId(p) == insertRef ){
            /*
             * Updates are a little more complicated, because you have to
             * propagate changes in the expected size up the expression tree.
             * For example, the SQL snippet:
             *     _49:bat[:oid,:oid]{rows=0,bid=622}  := sql.bind_dbat("sys","example",3);
             *     _54 := bat.setWriteMode(_49);
             *     bat.append(_54,_47,true);
             * shows what is produced when it encounters a deletion. If a non-empty
             * append is not properly passed back to _49, the emptySet
             * optimizer might remove the complete deletion code.
             * The same holds for replacement operations, which add information to
             * an initially empty insertion BAT.
             */
            if( isaBatType(getArgType(mb,p,2)) ){
                /* insert BAT */
                newRows(1,2, (c1 + c2+1),1);
                OPTbackpropagate(mb,i,getArg(p,1));
            } else {
                /* insert scalars */
                newRows(1,1, (c1 +1),1);
                OPTbackpropagate(mb,i,getArg(p,1));
            }
        } else if (getFunctionId(p) == deleteRef){
            if( isaBatType(getArgType(mb,p,2)) ){
                /* delete BAT */
                newRows(1,2, (c1 - c2 ==0? 1: c1-c2),1);
                OPTbackpropagate(mb,i,getArg(p,1));
            } else {
                /* insert scalars */
                newRows(1,1, (c1==1?1: c1-1),1);
                OPTbackpropagate(mb,i,getArg(p,1));
            }
            OPTbackpropagate(mb,i,getArg(p,1));
        } else if (getFunctionId(p) == insertRef){
            newRows(1,1,( c1 + 1),0); /* faked */
            OPTbackpropagate(mb,i,getArg(p,1));
        }
    } else if (getModuleId(p)==groupRef) {
        if (getFunctionId(p) ==newRef) {
            newRows(1,1,( c1 / 10+1),0);
        } else {
            newRows(1,1, c1,0);
        }
    } else if (getModuleId(p)== aggrRef) {
        if (getFunctionId(p) == sumRef ||
            getFunctionId(p) == minRef ||
            getFunctionId(p) == maxRef ||
            getFunctionId(p) == avgRef) {
            newRows(1,1, ( c1?c1:c1+1),0);
        } else  if (getFunctionId(p) == countRef){
            newRows(1,1, 1,0);
        }
    } else if( p-&gt;token == ASSIGNsymbol &amp;&amp; p-&gt;argc== 2){
        /* copy the rows property */
        c1 = getVarRows(mb, getArg(p,1));
        if (c1 != -1) {
            ValRecord v;

            varSetProp(mb, getArg(p,0), rowsProp, op_eq, VALset(&amp;v, TYPE_wrd, &amp;c1));
        }
    }
}
DEBUGoptimizers
    mnstr_printf(cntxt-&gt;fdout,"#opt_costModel: processed\n");
return 1;
</code></pre>

<p>{% endcodeblock %}</p>

<blockquote><p><p>8.数据流优化器 ：</p>
<p>MAL程序很大程度上是执行计划的逻辑描述。至少它关注没有副影响的操作。对于这些子计划执行的顺序需要的不是一个固定的优先级而可能是数据流驱动的评估。甚至使用多核互不影响地工作在数据流图中。数据流优化器分析代码和为了数据流驱动执行用保护块包装健壮的代码。当然，这只是必要的如果你可以前端决定可能有多线程的运行。</p>
<p>对于运行，解析器根据可用处理器核的数量来初始化多线程。接下来，合格的指令被排序和被解析器线程解析。数据流块可能不是成堆的。因此，为内联代码产生的任何数据流块首先被去除。</p>
{% codeblock MonetDB数据流优化器实现代码 lang:c %}
int OPTdataflowImplementation(Client cntxt, MalBlkPtr mb, MalStkPtr stk, InstrPtr p)
{</p>

<pre><code>int i,j,k, cnt, start=1,entries=0, actions=0;
int flowblock= 0, dumbcopy=0;
InstrPtr *old, q;
int limit, slimit;
Lifespan span;
char *init;
</code></pre></blockquote>

<pre><code>/* don't use dataflow on single processor systems */
if (GDKnr_threads &lt;= 1)
    return 0;

(void) cntxt;
(void) stk;
/* inlined functions will get their dataflow control later */
if ( varGetProp(mb, getArg(getInstrPtr(mb,0),0),inlineProp)!= NULL) 
    return 0;
span= setLifespan(mb);
if( span == NULL)
    return 0;
init= (char*) GDKzalloc(mb-&gt;vtop);
if ( init == NULL){
    GDKfree(span);
    return 0;
}
limit= mb-&gt;stop;
slimit= mb-&gt;ssize;
old = mb-&gt;stmt;
if ( newMalBlkStmt(mb, mb-&gt;ssize+20) &lt;0 ){
    GDKfree(span);
    GDKfree(init);
    return 0;
}
pushInstruction(mb,old[0]);

removeDataflow(old,limit);

/* inject new dataflow barriers */
for (i = 1; i&lt;limit; i++) {
    p = old[i];

    if (p == NULL)
        continue;

    if (p-&gt;token == ENDsymbol)
        break;
    if (hasSideEffects(p,FALSE) || isUnsafeFunction(p) || blockCntrl(p) || (!dumbcopy &amp;&amp; blockExit(p)) || (getModuleId(p) == sqlRef &amp;&amp; isUpdateInstruction(p)) || dflowAssignTest(span,p,i) ){
        /* close old flow block */
        if (flowblock){
            int sf = simpleFlow(old,start,i);
            if (!sf &amp;&amp; entries &gt; 1){
                for( j=start ; j&lt;i; j++)
                if (old[j]) 
                    for( k=0; k&lt;old[j]-&gt;retc; k++)
                    if( getBeginLifespan(span,getArg(old[j],k)) &gt; start &amp;&amp; getEndLifespan(span,getArg(old[j],k)) &gt;= i &amp;&amp; init[getArg(old[j],k)]==0){
                        InstrPtr r= newAssignment(mb);
                        getArg(r,0)= getArg(old[j],k);
                        pushNil(mb,r,getArgType(mb,old[j],k));
                        init[getArg(old[j],k)]=1;
                    }
                q= newFcnCall(mb,languageRef,dataflowRef);
                q-&gt;barrier= BARRIERsymbol;
                getArg(q,0)= flowblock;
                /* dataflow blocks are transparent, because they are always
                   executed, either sequentially or in parallell */
                varSetProperty(mb, getArg(q,0), "transparent",0,0);
            }
            for( j=start ; j&lt;i; j++)
                if (old[j])
                    pushInstruction(mb,old[j]);
            if (!sf &amp;&amp; entries&gt;1){
                q= newAssignment(mb);
                q-&gt;barrier= EXITsymbol;
                getArg(q,0) = flowblock;
            }
            entries = 0;
            flowblock = 0;
            actions++;
        }
        pushInstruction(mb,p);
        continue;
    }

    if (blockStart(p)){
        dumbcopy++;
        if (dumbcopy == 1)
            /* close old flow block */
            if (flowblock){
                int sf = simpleFlow(old,start,i);
                if (!sf &amp;&amp; entries &gt; 1){
                    for( j=start ; j&lt;i; j++)
                    if (old[j]) 
                        for( k=0; k&lt;old[j]-&gt;retc; k++)
                        if( getBeginLifespan(span,getArg(old[j],k)) &gt; start &amp;&amp; getEndLifespan(span,getArg(old[j],k)) &gt;= i &amp;&amp; init[getArg(old[j],k)]==0){
                            InstrPtr r= newAssignment(mb);
                            getArg(r,0)= getArg(old[j],k);
                            pushNil(mb,r,getArgType(mb,old[j],k));
                            init[getArg(old[j],k)]=1;
                        }
                    q= newFcnCall(mb,languageRef,dataflowRef);
                    q-&gt;barrier= BARRIERsymbol;
                    getArg(q,0)= flowblock;
                    /* dataflow blocks are transparent, because they are always
                       executed, either sequentially or in parallell */
                    varSetProperty(mb, getArg(q,0), "transparent",0,0);
                }
                for( j=start ; j&lt;i; j++)
                    if (old[j])
                        pushInstruction(mb,old[j]);
                if (!sf &amp;&amp; entries&gt;1){
                    q= newAssignment(mb);
                    q-&gt;barrier= EXITsymbol;
                    getArg(q,0) = flowblock;
                }
                entries = 0;
                flowblock = 0;
                actions++;
            }
    }
    if (blockExit(p)) {
        assert(flowblock == 0);
        dumbcopy--;
        pushInstruction(mb,p);
        continue;
    }
    if (dumbcopy) {
        assert(flowblock == 0);
        pushInstruction(mb,p);
        continue;
    }
    if (flowblock == 0){
        flowblock = newTmpVariable(mb,TYPE_bit);
        entries = 0;
        start = i;
    }
    /* check if the instruction can start a flow */
    /* this should be a function call with multiple arguments */
    cnt = 0;
    if (getFunctionId(p))
        for(j=p-&gt;retc; j&lt;p-&gt;argc; j++) 
            if ( isVarConstant(mb, getArg(p,j)) || getLastUpdate(span, getArg(p,j)) &lt;= start)
                cnt++;
    if (cnt &amp;&amp; dflowAssignTest(span,p,i))
        cnt = 0;

    if (cnt &amp;&amp; cnt == p-&gt;argc-p-&gt;retc)
        entries++;
}
/* close old flow block */
if (flowblock){
    int sf = simpleFlow(old,start,i);
    if (!sf &amp;&amp; entries &gt; 1){
        for( j=start ; j&lt;i; j++)
        if (old[j]) 
            for( k=0; k&lt;old[j]-&gt;retc; k++)
            if( getBeginLifespan(span,getArg(old[j],k)) &gt; start &amp;&amp; getEndLifespan(span,getArg(old[j],k)) &gt;= i &amp;&amp; init[getArg(old[j],k)]==0){
                InstrPtr r= newAssignment(mb);
                getArg(r,0)= getArg(old[j],k);
                pushNil(mb,r,getArgType(mb,old[j],k));
                init[getArg(old[j],k)]=1;
            }
        q= newFcnCall(mb,languageRef,dataflowRef);
        q-&gt;barrier= BARRIERsymbol;
        getArg(q,0)= flowblock;
        /* dataflow blocks are transparent, because they are always
           executed, either sequentially or in parallell */
        varSetProperty(mb, getArg(q,0), "transparent",0,0);
    }
    for( j=start ; j&lt;i; j++)
        if (old[j])
            pushInstruction(mb,old[j]);
    if (!sf &amp;&amp; entries&gt;1){
        q= newAssignment(mb);
        q-&gt;barrier= EXITsymbol;
        getArg(q,0) = flowblock;
    }
    entries = 0;
    flowblock = 0;
    actions++;
}
/* take the remainder as is */
for (; i&lt;limit; i++) 
    if (old[i])
        pushInstruction(mb,old[i]);
for (; i&lt;slimit; i++) 
    if (old[i])
        freeInstruction(old[i]);
GDKfree(old);
GDKfree(span);
GDKfree(init);
DEBUGoptimizers
    mnstr_printf(cntxt-&gt;fdout,"#opt_dataflow: %d flow blocks created\n",actions);
return actions;
</code></pre>

<p>}
{% endcodeblock %}</p>

<blockquote><p><p>9.去除无用代码</p>
<p>无用代码碎片通过赋值到不再使用的变量被识别。它可以被探测通过标记作为使用的参数作为相关的所有的变量。同时，我们建立应该在最后结果出现的一系列指令。新建的代码块在一次扫描中建立，去除无用的指令。指令对环境产生副影响，如，输出和更新BAT应该被考虑进来。这样（可能递归）函数应该被标记有一个（不安全）的属性。现在我们识别了几个重要的，否则，指令被标记为控制流指令应该被保留。一个说明性例子的MAL片段如下：</p>
{% codeblock  lang:c %}</p>

<pre><code>V7 := bat.new(:oid,:int);
V10 := bat.new(:int,:oid);
V16 := algebra.markH(V7);
V17 := algebra.join(V16,V7);
V19 := bat.new(:oid,:int);
V22 := bat.new(:oid,:int);
V23 := algebra.join(V16,V22);
io.print("done");
optimizer.deadCodeRemoval();
</code></pre>

<p>{% endcodeblock %}
<p>去除无用的代码使程序缩小到一下的短小的代码块：</p>
{% codeblock  lang:c %}</p>

<pre><code>io.print("done");
</code></pre>

<p>{% endcodeblock %}
<p>对无用代码的提炼来源与使用停止存在的参数因为行为被优化器做了。如，在下面的代码片段PUSHRANGES优化器可能得出变量V31变为空的和简单地通过去掉赋值语句注入一个‘无用’变量。这同时使其他代码无用。</p>
{% codeblock  lang:c %}</p>

<pre><code>V30 := algebra.select( V7, 10,100);
V31 := algebra.select(V30,-1,5);
V32 := aggr.sum(V31);
io.print(V32);
</code></pre>

<p>{% endcodeblock %}
{% codeblock MonetDB去除无用的代码实现 lang:c %}
int OPTdeadcodeImplementation(Client cntxt, MalBlkPtr mb, MalStkPtr stk, InstrPtr pci)
{</p>

<pre><code>int i, k, se,limit, slimit;
InstrPtr p=0, *old= mb-&gt;stmt;
int actions = 0;
</code></pre></blockquote>

<pre><code>(void) pci;
(void) stk;     /* to fool compilers */

if (varGetProp(mb, getArg(mb-&gt;stmt[0], 0), inlineProp) != NULL)
    return 0;

clrDeclarations(mb);
chkDeclarations(cntxt-&gt;fdout, mb);
limit= mb-&gt;stop;
slimit = mb-&gt;ssize;
if ( newMalBlkStmt(mb, mb-&gt;ssize) &lt; 0)
    return 0;

pushInstruction(mb, old[0]);
for (i = 1; i &lt; limit; i++) {
    p= old[i];

    se = p-&gt;token == ENDsymbol;
    if( se){
        pushInstruction(mb,p);
        for(i++; i&lt;limit; i++)
            if(old[i])
                pushInstruction(mb,old[i]);
        break;
    }
    if( p-&gt;token != NOOPsymbol)
    for (k = 0; k &lt; p-&gt;retc; k++)
        if( isVarUsed(mb,getArg(p,k)) ){
            se++;
            break;
        } 

    if ( p-&gt;token == NOOPsymbol){
        freeInstruction(p);
        actions++;
    } else
    if( getModuleId(p)== sqlRef &amp;&amp; getFunctionId(p)== assertRef &amp;&amp;
        isVarConstant(mb,getArg(p,1)) &amp;&amp; getVarConstant(mb,getArg(p,1)).val.ival==0){
        freeInstruction(p);
        actions++;
    } else
    if (se || hasSideEffects(p, FALSE) || isUpdateInstruction(p) || !isLinearFlow(p) || 
            isProcedure(mb,p)  || 
            (p-&gt;retc == 1 &amp;&amp; varGetProp( mb, getArg(p,0), unsafeProp ) != NULL) ||
            p-&gt;barrier /* ==side-effect */)
        pushInstruction(mb,p);
    else {
        freeInstruction(p);
        actions++;
    }
}
for(; i&lt;slimit; i++)
    if( old[i])
        freeInstruction(old[i]);
DEBUGoptimizers
    mnstr_printf(cntxt-&gt;fdout,"#opt_deadcode: %d statements removed\n", actions);
GDKfree(old);
/* we may have uncovered new use-less operations */
if (actions) 
    actions += OPTdeadcodeImplementation(cntxt,mb, stk, pci);
return actions;
</code></pre>

<p>}
{% endcodeblock %}</p>

<blockquote><p><p>10.去除空集：</p>
<p>在MAL优化期间其中最关键决定是估计产生和消耗的BAT的大小。两种情况对标志处理有兴趣。也就是，当一个BAT被知道没有包含元组和元组只有一个元素。这样的信息可能来自应用领域只是或者作为从标志评估另外的影响。这关联到作为属性被探测的程序。空集属性被呈现的消减算法使用。任何空集在程序中被传播到达一个更小和因此更快的评估。如，考虑接下来的MAL测试：</p>
{% codeblock  lang:c %}</p>

<pre><code>V1 := bat.new(:oid,:int);
V7 := bat.new(:oid,:int);
V10{rows=0} := bat.new(:int,:oid);
V11 := bat.reverse(V10);
V12 := algebra.kdifference(V7,V11);
V16 := algebra.markH(V12);
V17 := algebra.join(V16,V7);
bat.append(V1,V17);
optimizer.costModel();
optimizer.emptySet();
</code></pre>

<p>{% endcodeblock %}
<p>调用优化器用接下来的程序片段取代上面的程序</p>
{% codeblock  lang:c %}</p>

<pre><code>V1 := bat.new(:oid,:int);
V7 := bat.new(:oid,:int);
V10{rows=0} := bat.new(:int,:oid);
V11{rows=0} := bat.new(:oid,:int);
V12 := V7;
V16 := algebra.markH(V12);
V17 := algebra.join(V16,V7);
bat.append(V1,V17);
</code></pre>

<p>{% endcodeblock %}
<p>这代码块可以使用别名传播和去除无用代码继续优化。最后的代码块如下：</p>
{% codeblock  lang:c %}</p>

<pre><code>V1 := bat.new(:oid,:int);
V7 := bat.new(:oid,:int);
V16 := algebra.markH(V7);
V17 := algebra.join(V16,V7);
bat.append(V1,V17);
</code></pre>

<p>{% endcodeblock %}
<p>在空集传播时，新的候选者可能出现。如，与空集进行交运算还是得到空集。它成为中间优化的目标。当前的实现是保守的。一个有限的指令集合被考虑。任何添加到MonetDB指令集调用评估它们的影响。</p>
{% codeblock MonetDB去除空集的代码实现 lang:c %}
static int  ESevaluate(Client cntxt, MalBlkPtr mb, char *empty)
{</p>

<pre><code>int i, j, actions = 0;
InstrPtr p;
str existRef = putName("exist", 5);
str uniqueRef = putName("unique", 6);
str suniqueRef = putName("sunique", 7);
str intersectRef = putName("intersect", 9);
str sintersectRef = putName("sintersect", 10);
str kintersectRef = putName("kintersect", 10);
str fragmentRef = putName("fragment", 8);
int *alias;
int runonce= FALSE;
</code></pre></blockquote>

<pre><code>int limit = mb-&gt;stop, slimit= mb-&gt;ssize, ctop=0;
InstrPtr *old = mb-&gt;stmt, *constraints;

(void) cntxt;
/* get query property */
runonce = (varGetProp(mb, getArg(old[0], 0), runonceProp) != NULL);
if (varGetProp(mb, getArg(old[0], 0), inlineProp) != NULL)
    return 0;

if ( newMalBlkStmt(mb, mb-&gt;ssize) &lt; 0)
    return 0;
constraints= (InstrPtr *) GDKmalloc(sizeof(InstrPtr)*slimit);
if ( constraints == NULL) {
    GDKfree(mb-&gt;stmt);
    mb-&gt;stmt = old;
    mb-&gt;stop = limit;
    mb-&gt;ssize = slimit;
    return 0;
}
alias = (int*) GDKmalloc(sizeof(int)*mb-&gt;vtop);
if( alias == NULL){
    GDKfree(mb-&gt;stmt);
    mb-&gt;stmt = old;
    mb-&gt;stop = limit;
    mb-&gt;ssize = slimit;
    GDKfree(constraints);
    return 0;
}
for(i=0;i&lt;mb-&gt;vtop; i++) 
    alias[i]=i;

/* Symbolic evaluation of the empty BAT variables */
/* by looking at empty BAT arguments */
for (i = 0; i &lt; limit; i++) {
    char *f;
    p = old[i];

    pushInstruction(mb,p);
    if (p-&gt;token == ENDsymbol){
        for(i++; i&lt;limit; i++)
            if (old[i])
                pushInstruction(mb,old[i]);
        break;
    }
    for(j=0; j&lt;p-&gt;argc; j++)
        p-&gt;argv[j] = alias[getArg(p,j)];
    /*
     * The bulk of the intelligence lies in inspecting calling
     * sequences to filter and replace calls with empty arguments.
     */
    f = getFunctionId(p);
    if (getModuleId(p) == sqlRef &amp;&amp; 
        empty[getArg(p,0)] &amp;&amp;
       (f == bindRef || f == bindidxRef || f == binddbatRef)){
        InstrPtr q;
        /*
         * @-
         * The emptyset assertion is only needed once for relational insertions.
         * We assume here that string constants have been matched already.
         */
        if( f == bindRef &amp;&amp; runonce == FALSE) {
            for( j=ctop-1; j&gt;=0; j--){
                q= constraints[j];
                if( strcmp(getVarConstant(mb,getArg(q,2)).val.sval, getVarConstant(mb,getArg(p,2)).val.sval)==0 &amp;&amp;
                    strcmp(getVarConstant(mb,getArg(q,3)).val.sval, getVarConstant(mb,getArg(p,3)).val.sval)==0 &amp;&amp;
                    getVarConstant(mb,getArg(p,5)).val.ival&lt;=2 &amp;&amp; /* no updates etc */
                    getVarConstant(mb,getArg(q,5)).val.ival == getVarConstant(mb,getArg(p,5)).val.ival
                ) 
                    /* don't generate the assertion */
                    goto ignoreConstraint;
            }

            q = newStmt1(mb, constraintsRef, "emptySet");
            (void) pushArgument(mb, q, getArg(p,0) );
            constraints[ctop++]= p;
        }
    ignoreConstraint:
        continue;
    } 

    for (j = p-&gt;retc; j &lt; p-&gt;argc; j++) {

        if (empty[getArg(p, j)]) {
            /* decode operations */
            if (getModuleId(p)== algebraRef) {
                if (f == existRef) {
                    /* always false */
                    setModuleId(p, NULL);
                    setFunctionId(p, NULL);
                    p-&gt;argc = 1;
                    p-&gt;token = ASSIGNsymbol;
                    (void) pushBit(mb, p, FALSE);
                    actions++;
                    break;
                } 
                if ( f == selectRef || 
                     f == tuniqueRef || 
                     f == likeRef  || 
                     f == sortRef  || 
                     f == sortTailRef  ||
                     f == sortHTRef  || 
                     f == sortTHRef  || 
                     f == uniqueRef  || 
                     f == suniqueRef  || 
                     f == kuniqueRef  ||
                     f == intersectRef  || 
                     f == semijoinRef ||
                     f == sintersectRef  || 
                     f == kintersectRef  ||
                     f == fragmentRef ){

                    /* result is empty */
                    propagate(1);
                    break;
                } 
                if ( f == differenceRef || 
                     f == kdifferenceRef ) {
                    propagate(1);
                    break;
                }
                if ( f == sunionRef || 
                     f == kunionRef || 
                     f == unionRef) {
                    /* copy non-empty argument */
                    if( j == 1) {
                        propagate(2);
                    } else {
                        propagate(1);
                    }
                    break;
                } 
            }
            if (getModuleId(p)== batRef) {
                if ( f == reverseRef || f == mirrorRef ){
                    empty[getArg(p, 0)]= 1;
                }
            }
            /*
             * @-
             * If the target variable is empty and the function does not
             * have a side-effect, we can replace it with a construction
             * of the empty set. The dead-code optimizer will take care
             * of removal of superflous constructions.
             */
            if( p-&gt;retc==1 &amp;&amp; p-&gt;token == ASSIGNsymbol &amp;&amp;
                !isLinearFlow(p) &amp;&amp;
                isaBatType(getArgType(mb,p,0))){
                int tpe=getArgType(mb,p,0);
                clrFunction(p);
                setModuleId(p, batRef);
                setFunctionId(p, newRef);
                p= pushArgument(mb, p, 
                    newTypeVariable(mb, getHeadType(tpe)));
                (void) pushArgument(mb, p, 
                    newTypeVariable(mb, getTailType(tpe)));
                actions++;
                break;
            }
        }
    }
}
for(; i&lt;slimit; i++)
    if (old[i])
        freeInstruction(old[i]);
GDKfree(old);
if (actions) {
    DEBUGoptimizers
    mnstr_printf(cntxt-&gt;fdout,"#opt_emptyset: %d empty sets statements removed\n",actions);
    clrAllTypes(mb);     /* force a complete resolve */
}
GDKfree(constraints);
GDKfree(alias);
return actions;
</code></pre>

<p>}
 /<em>We first have to find all candidates for empty set removal.
  They are recognized by an estimated zero row count and they
  are not the target of an update.</em>/</p>

<p>int OPTemptySetImplementation(Client cntxt, MalBlkPtr mb, MalStkPtr stk, InstrPtr p)
{</p>

<pre><code>char *empty;
int i;

empty = (char *) GDKzalloc(mb-&gt;vsize * sizeof(char));
if ( empty == NULL)
    return 0;
(void) stk;
(void) p;
for (i = 0; i &lt; mb-&gt;vtop; i++) {
    if (getVarRows(mb, i) == 0) {
        OPTDEBUGemptySet
            mnstr_printf(cntxt-&gt;fdout, "#START emptyset optimizer %d", i);
        empty[i] = 1;
    } 
}
OPTDEBUGemptySet mnstr_printf(cntxt-&gt;fdout, "\n");
i= ESevaluate(cntxt, mb, empty);
GDKfree(empty);
return i;
</code></pre>

<p>}
{% endcodeblock %}</p>

<blockquote><p><p>11.垃圾回收：</p>
<p>对临时的变量的垃圾回收，如字符串和BATs，在返回函数调用的时候发生。特别对于BATs这可能保留可观的资源锁定长于严格必要的时间。尽管程序员可以影响它们的生命周期通过给它们赋值NIL，从而触发垃圾会后，依靠优化器去注入这样的语句更加恰当。因为它使程序更加短小和有一个更好的代码优化的目标。OPTIMIZER.GARBAGECOLLECTOR()操作去除所有结束生命周期的BAT为新的提供空间。这特别被调用为优化的最后一步。垃圾回收影响的一小段代码：</p>
{% codeblock  lang:c %}</p>

<pre><code>t1 := bat.new(:oid,:int);
t2 := array.grid(132000,8,1,0);
t3 := array.grid(1,100,10560,0);
t4 := array.grid(1,100,10560,0,8);
t5 := batcalc.+(t2,t4);
t6 := batcalc.oid(t5);
t7 := algebra.join(t6,t1);
optimizer.garbageCollector();
</code></pre>

<p>{% endcodeblock %}
<p>被转换为以下的代码块</p>
{% codeblock  lang:c %}</p>

<pre><code>t1 := bat.new(:oid,:int);
t2 := array.grid(132000,8,1,0);
t3 := array.grid(1,100,10560,0);
t4 := array.grid(1,100,10560,0,8);
t5 := batcalc.+(t2,t4);
bat.setGarbage(t2);
bat.setGarbage(t4);
t6 := batcalc.oid(t5);
bat.setGarbage(t5);
t7 := algebra.join(t6,t1);
bat.setGarbage(t6);
bat.setGarbage(t1);
</code></pre>

<p>{% endcodeblock %}
<p>当前的算法是直接的。在每一条指令后，我们检查在未来其BAT参数是否需要。如果不需要，我们注入垃圾回收语句去释放她们呢，如果没有其它理由去保留它。这应该小心地去做，因为指令可能是循环的一部分。如果变量在循环里定义，那么我们可以安全地去掉它。</p>
{% codeblock MonetDB垃圾回收代码实现  lang:c %}
 /<em>Keeping variables around beyond their end-of-life-span
 can be marked with the proper 'keep'.</em>/
int OPTgarbageCollectorImplementation(Client cntxt, MalBlkPtr mb, MalStkPtr stk, InstrPtr pci)
{</p>

<pre><code>int i, j, k, n = 0, limit, vlimit, depth=0, slimit;
InstrPtr p, q, *old;
int actions = 0;
Lifespan span;
</code></pre></blockquote>

<pre><code>(void) pci;
(void) cntxt;
(void) stk;
if (varGetProp(mb, getArg(mb-&gt;stmt[0], 0), inlineProp) != NULL)
    return 0;

span = setLifespan(mb);
if ( span == NULL)
    return 0;

old= mb-&gt;stmt;
limit = mb-&gt;stop;
slimit = mb-&gt;ssize;
vlimit = mb-&gt;vtop;
if ( newMalBlkStmt(mb,mb-&gt;ssize) &lt; 0) {
    GDKfree(span);
    return 0;
}

p = NULL;
for (i = 0; i &lt; limit; i++) {
    p = old[i];
    p-&gt;gc &amp;=  ~GARBAGECONTROL;

    if ( p-&gt;barrier == RETURNsymbol){
        pushInstruction(mb, p);
        continue;
    }
    if (blockStart(p) )
        depth++;
    if ( p-&gt;token == ENDsymbol)
        break;

    pushInstruction(mb, p);
    n = mb-&gt;stop-1;
    for (j = 0; j &lt; p-&gt;argc; j++) {
        if (getEndLifespan(span,getArg(p,j)) == i &amp;&amp; isaBatType(getArgType(mb, p, j)) ){
            mb-&gt;var[getArg(p,j)]-&gt;eolife = n;
            p-&gt;gc |= GARBAGECONTROL;
        } 
    }
    if (blockExit(p) ){
        /* force garbage collection of all within upper block */
        depth--;
        for (k = 0; k &lt; vlimit; k++) {
            if (getEndLifespan(span,k) == i &amp;&amp;
                isaBatType(getVarType(mb,k)) &amp;&amp;
                varGetProp(mb, k, keepProp) == NULL){
                    q= newAssignment(mb);
                    getArg(q,0) = k;
                    setVarUDFtype(mb,k);
                    setVarFixed(mb,k);
                    q= pushNil(mb,q, getVarType(mb,k));
                    q-&gt;gc |= GARBAGECONTROL;
                    mb-&gt;var[k]-&gt;eolife = mb-&gt;stop-1;
                    actions++;
            }
        }
    }
}
assert(p);
assert( p-&gt;token == ENDsymbol);
pushInstruction(mb, p);
for (i++; i &lt; limit; i++) 
    pushInstruction(mb, old[i]);
for (; i &lt; slimit; i++) 
    if (old[i])
        freeInstruction(old[i]);
getInstrPtr(mb,0)-&gt;gc |= GARBAGECONTROL;
GDKfree(old);
OPTDEBUGgarbageCollector{ 
    int k;
    mnstr_printf(cntxt-&gt;fdout, "#Garbage collected BAT variables \n");
    for ( k =0; k &lt; vlimit; k++)
    mnstr_printf(cntxt-&gt;fdout,"%10s eolife %3d  begin %3d lastupd %3d end %3d\n",
        getVarName(mb,k), mb-&gt;var[k]-&gt;eolife,
        getBeginLifespan(span,k), getLastUpdate(span,k), getEndLifespan(span,k));
    mnstr_printf(cntxt-&gt;fdout, "End of GCoptimizer\n");
}
GDKfree(span);

DEBUGoptimizers
    mnstr_printf(cntxt-&gt;fdout,"#opt_garbagecollector: %d variables reset\n",actions);
return actions+1;
</code></pre>

<p>}
{% endcodeblock %}</p>

<blockquote><p><p>13.连接路径：</p>
<p>任务OPTIMIZER.JOINPATH()浏览代码寻找连接操作和级联它们到多连接路径。为了说明，考虑：</p>
{% codeblock  lang:c %}</p>

<pre><code>a:= bat.new(:oid,:oid);
b:= bat.new(:oid,:oid);
c:= bat.new(:oid,:str);
j1:= algebra.join(a,b);
j2:= algebra.join(j1,c);
j3:= algebra.join(b,b);
j4:= algebra.join(b,j3);
</code></pre>

<p>{% endcodeblock %}
<p>优化器首先会通过它们连接的顺序替代所有的参数。下面的指令留给去除无用代码优化器优化</p>
{% codeblock  lang:c %}</p>

<pre><code>a:= bat.new(:oid,:oid);
j1:= algebra.join(a,b);
j2:= algebra.joinPath(a,b,c);
j3:= algebra.join(b,b);
j4:= algebra.joinPath(b,b,b);
</code></pre>

<p>{% endcodeblock %}
<p>在原则上，连接路径可能包含改善性能的公共的子路径。SQL front-end 经常产生以下代码片段：</p>
{% codeblock  lang:c %}</p>

<pre><code>t1:= algebra.join(b,c);
z1:= algebra.join(a,t1);
...
t2:= algebra.join(b,d);
z2:= algebra.join(a,t2);
</code></pre>

<p>{% endcodeblock %}
<p>连接路径合并成：</p>
{% codeblock  lang:c %}</p>

<pre><code>z1:= algebra.joinPath(a,b,c);
...
z2:= algebra.joinPath(a,b,d);
</code></pre>

<p>{% endcodeblock %}
<p>由启发式寻找最先的两个参数控制和重用实质的连接</p>
{% codeblock  lang:c %}</p>

<pre><code>_13:= algebra.join(a,b);
z1:= algebra.join(_13,c);
...
z2:= algebra.join(_13,d);
</code></pre>

<p>{% endcodeblock %}
<p>一个替代是公共重新使用的路径重识别到连接路径主体继承的部分</p>
{% codeblock  lang:c %}</p>

<pre><code>x3:= algebra.join(a,b);
r3:= bat.reverse(x3);
j1:= join(c,r3);
rb:= bat.reverse(b);
ra:= bat.reverse(a);
j1:= algebra.joinpath(c,rb,ra);
</code></pre>

<p>{% endcodeblock %}
{% codeblock MonetDB连接路径优化代码的实现 lang:c %}
int OPTjoinPathImplementation(Client cntxt, MalBlkPtr mb, MalStkPtr stk, InstrPtr p)
{</p>

<pre><code>int i,j,k, actions=0;
int *pc;
str joinPathRef = putName("joinPath",8);
str leftjoinPathRef = putName("leftjoinPath",12);
str semijoinPathRef = putName("semijoinPath",12);
InstrPtr q,r;
InstrPtr *old;
int *varcnt;        /* use count */
int limit,slimit;
</code></pre></blockquote>

<pre><code>(void) cntxt;
(void) stk;
if (varGetProp(mb, getArg(mb-&gt;stmt[0], 0), inlineProp) != NULL)
    return 0;

old= mb-&gt;stmt;
limit= mb-&gt;stop;
slimit= mb-&gt;ssize;
if ( newMalBlkStmt(mb,mb-&gt;ssize) &lt; 0)
    return 0;

/* beware, new variables and instructions are introduced */
pc= (int*) GDKzalloc(sizeof(int)* mb-&gt;vtop * 2); /* to find last assignment */
varcnt= (int*) GDKzalloc(sizeof(int)* mb-&gt;vtop * 2); 
if (pc == NULL || varcnt == NULL){
    if (pc ) GDKfree(pc);
    if (varcnt ) GDKfree(varcnt);
    return 0;
}
/*
 * @-
 * Count the variable use as arguments first.
 */
for (i = 0; i&lt;limit; i++){
    p= old[i];
    for(j=p-&gt;retc; j&lt;p-&gt;argc; j++)
        varcnt[getArg(p,j)]++;
}

for (i = 0; i&lt;limit; i++){
    p= old[i];
    if( getModuleId(p)== algebraRef &amp;&amp; (getFunctionId(p)== joinRef || getFunctionId(p) == leftjoinRef || getFunctionId(p) == semijoinRef)){
        /*
         * @-
         * Try to expand its argument list with what we have found so far.
         * This creates a series of join paths, many of which will be removed during deadcode elimination.
         */
        q= copyInstruction(p);
        q-&gt;argc=1;
        for(j=p-&gt;retc; j&lt;p-&gt;argc; j++){
            r= getInstrPtr(mb,pc[getArg(p,j)]);
            /*
             * @-
             * Don't inject a pattern when it is used more than once.
             */
            if (r &amp;&amp; varcnt[getArg(p,j)] &gt; 1){
                OPTDEBUGjoinPath {
                    mnstr_printf(cntxt-&gt;fdout,"#double use %d %d\n", getArg(p,j), varcnt[getArg(p,j)]);
                    printInstruction(cntxt-&gt;fdout,mb, 0, p, LIST_MAL_ALL);
                }
                r = 0;
            }
            OPTDEBUGjoinPath {
                mnstr_printf(cntxt-&gt;fdout,"#expand list \n");
                printInstruction(cntxt-&gt;fdout,mb, 0, p, LIST_MAL_ALL);
                printInstruction(cntxt-&gt;fdout,mb, 0, q, LIST_MAL_ALL);
            }
            if ( getFunctionId(p) == joinRef){
                if( r &amp;&amp;  getModuleId(r)== algebraRef &amp;&amp; ( getFunctionId(r)== joinRef  || getFunctionId(r)== joinPathRef) ){
                    for(k= r-&gt;retc; k&lt;r-&gt;argc; k++) 
                        q = pushArgument(mb,q,getArg(r,k));
                } else 
                    q = pushArgument(mb,q,getArg(p,j));
            } else if ( getFunctionId(p) == leftjoinRef){
                if( r &amp;&amp;  getModuleId(r)== algebraRef &amp;&amp; ( getFunctionId(r)== leftjoinRef  || getFunctionId(r)== leftjoinPathRef) ){
                    for(k= r-&gt;retc; k&lt;r-&gt;argc; k++) 
                        q = pushArgument(mb,q,getArg(r,k));
                } else 
                    q = pushArgument(mb,q,getArg(p,j));
            } else if ( getFunctionId(p) == semijoinRef){
                if( r &amp;&amp;  getModuleId(r)== algebraRef &amp;&amp; ( getFunctionId(r)== semijoinRef  || getFunctionId(r)== semijoinPathRef) ){
                    for(k= r-&gt;retc; k&lt;r-&gt;argc; k++) 
                        q = pushArgument(mb,q,getArg(r,k));
                } else 
                    q = pushArgument(mb,q,getArg(p,j));
            }
        }
        OPTDEBUGjoinPath {
            chkTypes(cntxt-&gt;fdout, cntxt-&gt;nspace,mb,TRUE);
            mnstr_printf(cntxt-&gt;fdout,"#new [left]joinPath instruction\n");
            printInstruction(cntxt-&gt;fdout,mb, 0, q, LIST_MAL_ALL);
        }
        if(q-&gt;argc&lt;= p-&gt;argc){
            /* no change */
            freeInstruction(q);
            goto wrapup;
        }
        /*
         * @-
         * Final type check and hardwire the result type, because that  can not be inferred directly from the signature
         */
        for(j=1; j&lt;q-&gt;argc-1; j++)
            if( getTailType(getArgType(mb,q,j)) != getHeadType(getArgType(mb,q,j+1)) &amp;&amp;
            !( getTailType(getArgType(mb,q,j))== TYPE_oid  &amp;&amp;
            getHeadType(getArgType(mb,q,j))== TYPE_void) &amp;&amp;
            !( getTailType(getArgType(mb,q,j))== TYPE_void &amp;&amp;
            getHeadType(getArgType(mb,q,j))== TYPE_oid)){
            /* don't use it */
                freeInstruction(q);
                goto wrapup;
            }

        /* fix the type */
        setVarUDFtype(mb, getArg(q,0));
        setVarType(mb, getArg(q,0), newBatType( getHeadType(getArgType(mb,q,q-&gt;retc)), getTailType(getArgType(mb,q,q-&gt;argc-1))));
        if ( q-&gt;argc &gt; 3  &amp;&amp;  getFunctionId(q) == joinRef)
            setFunctionId(q,joinPathRef);
        else if ( q-&gt;argc &gt; 3  &amp;&amp;  getFunctionId(q) == leftjoinRef)
            setFunctionId(q,leftjoinPathRef);
        else if ( q-&gt;argc &gt; 2  &amp;&amp;  getFunctionId(q) == semijoinRef)
            setFunctionId(q,semijoinPathRef);
        freeInstruction(p);
        p= q;
        actions++;
    } 
wrapup:
    pushInstruction(mb,p);
    for(j=0; j&lt; p-&gt;retc; j++)
        pc[getArg(p,j)]= mb-&gt;stop-1;
}
for(; i&lt;slimit; i++)
    if(old[i])
        freeInstruction(old[i]);
/* perform the second phase, try out */
if (actions )
    actions += OPTjoinSubPath(cntxt, mb);
GDKfree(old);
GDKfree(pc);
if (varcnt ) GDKfree(varcnt);
DEBUGoptimizers
    mnstr_printf(cntxt-&gt;fdout,"#opt_joinpath: %d statements glued\n",actions);
return actions;
</code></pre>

<p>}
{% endcodeblock %}</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MonetDB 内存映射mmap]]></title>
    <link href="http://coolbrain.github.com/blog/2013/03/29/monetdbs-memory/"/>
    <updated>2013-03-29T23:47:00+08:00</updated>
    <id>http://coolbrain.github.com/blog/2013/03/29/monetdbs-memory</id>
    <content type="html"><![CDATA[<blockquote><p><p>在学计算机组成原理时，了解到为了平衡CPU的高速与内存慢速，在CPU与内存之间增加了L1 cache，L2 cache，以加快CPU对内存数据的访问。但同时了解到进程可以使用一系列相邻的虚拟地址来访问物理内存中不相邻的大内存缓冲区和访问大于可用物理内存地址的缓冲区（可与磁盘之间切换）。虚拟地址通过TLB转化为物理地址，若物理地址属于内存空间，即直接访问，若不在，即需要进行磁盘切换。层级的内存架构图：</p>
<!-- more -->
<img src="/assets/images/memory.jpg" alt="&quot;memory&quot;" />
mmap将文件或者其它对象映射到内存。当从内存中读写时，就相当于读写文件中相应的字节。
{% codeblock mmap函数声明 lang:c %}
   #include &lt;sys/mman.h>
   void <em>mmap(void </em>addr, size_t len, int prot, int flag,int fileds, off_t off);
{% endcodeblock %}
图示说明mmap：
<img src="/assets/images/mmap.png" alt="&quot;mmap&quot;" />
MonetDB使用mmap实现大内存块的分配和大文件的内存映射,这样有利于数据的快速查找。因为数据不在内存，直接进行磁盘切换（虚拟地址->物理地址）。
{% codeblock Linux大内存的分配 lang:c %}
  void <em>MT_vmalloc(size_t size, size_t </em>maxsize)
{</p>

<pre><code>MMAP_OPEN_DEV_ZERO;
char *q, *r = (char *) -1L;
</code></pre></blockquote>

<pre><code>if (fd &lt; 0) {
    return NULL;
}
size = MT_PAGESIZE(size);
*maxsize = MT_PAGESIZE(*maxsize);
if (*maxsize &gt; size) {
    r = (char *) mmap(NULL, *maxsize, PROT_NONE, 
                        MMAP_FLAGS(MAP_PRIVATE | MAP_NORESERVE), MMAP_FD, 0);
}
if (r == (char *) -1L) {
    *maxsize = size;
    q = (char *) mmap(NULL, size, PROT_READ | PROT_WRITE,
                        MMAP_FLAGS(MAP_PRIVATE), MMAP_FD, 0);
} else {
    q = (char *) mmap(r, size, PROT_READ | PROT_WRITE, 
                        MMAP_FLAGS(MAP_PRIVATE | MAP_FIXED), MMAP_FD, 0);
}
MMAP_CLOSE_DEV_ZERO;
return (void *) ((q == (char *) -1L) ? NULL : q);
</code></pre>

<p>}
{% endcodeblock %}</p>

<blockquote><p>{% codeblock Windows大内存的分配 lang:c %}
 void <em>MT_vmalloc(size_t size, size_t </em>maxsize)
{</p>

<pre><code>void *p, *a = NULL;
int mode = 0;
</code></pre></blockquote>

<pre><code>size = MT_PAGESIZE(size);
if (*maxsize &lt; size) {
    *maxsize = size;
}
*maxsize = MT_SEGSIZE(*maxsize);
if (*maxsize &lt; 1000000) {
    mode = MEM_TOP_DOWN;    /* help NT in keeping memory defragmented */
}
(void) pthread_mutex_lock(&amp;MT_mmap_lock);
if (*maxsize &gt; size) {
    a = (void *) VirtualAlloc(NULL, *maxsize, MEM_RESERVE | mode, PAGE_NOACCESS);
    if (a == NULL) {
        *maxsize = size;
    }
}
p = (void *) VirtualAlloc(a, size, MEM_COMMIT | mode, PAGE_READWRITE);
(void) pthread_mutex_unlock(&amp;MT_mmap_lock);
if (p == NULL) {
    mnstr_printf(GDKstdout, "#VirtualAlloc(" PTRFMT "," SZFMT ",MEM_COMMIT,PAGE_READWRITE): failed\n", PTRFMTCAST a, size);
}
return p;
</code></pre>

<p>}
{% endcodeblock %}</p>

<blockquote><p>MonetDB直接使用系统的mmap，由它来进行内存与磁盘的交互。而在这基础上，在进行内存分配管理。譬如在MonetDB中有使用sql_allocator建立内存缓冲区，当缓冲区内存不够时，才向系统申请。这样能加快内存申请速度和方便管理。此种方式是使用指针数组的管理内存，而没有使用链表。这与C++STL库的空间分配器类似，对于MonetDB内部数据结构，如list，hashtable，都是使用sql_allocator来管理其申请的内存。
{% codeblock sql_allocator结构体 lang:c %}
   typedef struct sql_allocator {</p>

<pre><code>size_t size;
size_t nr;
char **blks;
size_t used;    /* memory used in last block */
size_t usedmem; /* used memory */
</code></pre>

<p>} sql_allocator;
{% endcodeblock %}
具体的分配分三种情况处理，一：大于sz > SA_BLOCK,直接调用系统的GDKmalloc来分配；二：剩下来的内存不够分配sz > (SA_BLOCK-sa->used) 三：内存足够，只需进行必要的处理。
{% codeblock sa_alloc函数 lang:c %}
 #define round16(sz) ((sz+15)&amp;~15)
char <em>sa_alloc( sql_allocator </em>sa, size_t sz )
{</p>

<pre><code>char *r;
sz = round16(sz);
if (sz &gt; SA_BLOCK) {
    char *t;
    r = GDKmalloc(sz);
    if (sa-&gt;nr &gt;= sa-&gt;size) {
        sa-&gt;size *=2;
        sa-&gt;blks = RENEW_ARRAY(char*,sa-&gt;blks,sa-&gt;size);
    }
    t = sa-&gt;blks[sa-&gt;nr-1];
    sa-&gt;blks[sa-&gt;nr-1] = r;
    sa-&gt;blks[sa-&gt;nr] = t;
    sa-&gt;nr ++;
    return r;
}
if (sz &gt; (SA_BLOCK-sa-&gt;used)) {
    r = GDKmalloc(SA_BLOCK);
    if (sa-&gt;nr &gt;= sa-&gt;size) {
        sa-&gt;size *=2;
        sa-&gt;blks = RENEW_ARRAY(char*,sa-&gt;blks,sa-&gt;size);
    }
    sa-&gt;blks[sa-&gt;nr] = r;
    sa-&gt;nr ++;
    sa-&gt;used = sz;
    return r;
}
r = sa-&gt;blks[sa-&gt;nr-1] + sa-&gt;used;
sa-&gt;used += sz;
sa-&gt;usedmem += sz;
return r;
</code></pre>

<p>}
{% endcodeblock %}</p></blockquote>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MonetDB 捕捉信号]]></title>
    <link href="http://coolbrain.github.com/blog/2013/03/28/catch-signal-in-monetdb/"/>
    <updated>2013-03-28T23:24:00+08:00</updated>
    <id>http://coolbrain.github.com/blog/2013/03/28/catch-signal-in-monetdb</id>
    <content type="html"><![CDATA[<blockquote><p><p>MonetDB运行在Unix系统上，就需要进行一些系统的捕捉和处理。下列是常见的几种信号：</p>
<!-- more -->
<table border="1">
<tr><td>SIGCHLD:</td><td>在一个进程终止或停止时，将SIGCHLD信号发送给父进程。信号捕捉函数中通常要调用一种wait函数取得子进程ID和其终止的状态。</td></tr>
<tr><td>SIGHUP:</td><td>通常此信号通知守护进程，以重新读取它们的配置文件。</td></tr>
<tr><td>SIGINT:</td><td>当用户按中断键(一般是DELETE或Ctrl+C)时，终端驱动程序产生此信号并送至前台进程组中的每一个进程。</td></tr>
<tr><td>SIGKILL:</td><td>这是不能被捕捉或忽略的信号之一。它向系统管理员提供了一种可以杀死任一进程的可靠方法。</td></tr>
<tr><td>SIGQUIT:</td><td>当用户在终端上按退出键（Ctrl+)时，产生此信号，并送至前台进程组中的所有进程。此信号不仅会终止前台进程组，同时还会产生一个core文件。</td></tr>
</table>
UNIX的处理信号集的操作：
{% codeblock  lang:c %}</p>

<pre><code>#include &lt;signal.h&gt;
int sigemptyset(sigset_t *set);
int sigfillset(sigset_t *set);
int sigaddset(sigset_t *set, int signo);
int sigdelset(sigset_t *set, int signo);
int sigismember(sonct sigset_T *set,int signo);
</code></pre>

<p>{% endcodeblock %}
UNIX sigaction函数的功能是检查和修改与指定信号相关联的处理动作。
{% codeblock  lang:c %}</p>

<pre><code>#include &lt;signal.h&gt;
int sigaction(int signo, const struct sigaction* restrict act, 
                                struct sigaction *restrict oact);
struct sigaction{
    void (*sa_handler)(int);     /*addr of signal handler*/
    sigset_t sa_mask;            /*or SIG_IGN,or SIG_DFL*/
    int     sa_flags;            /*signal options*/
    void (*sa_sigaction)(int, siginfo_t *, void *);     /*alternate handler*/
}
</code></pre>

<p>{% endcodeblock %}
下面是MonetDB捕捉SIGINT，SIGQUIT，SIGTERM信号的代码，处理的是handler函数
{% codeblock  lang:c %}</p>

<pre><code>sigemptyset(&amp;sa.sa_mask);
sa.sa_flags = 0;
sa.sa_handler = handler;
if (
        sigaction(SIGINT, &amp;sa, NULL) == -1 ||
        sigaction(SIGQUIT, &amp;sa, NULL) == -1 ||
        sigaction(SIGTERM, &amp;sa, NULL) == -1)
{
    Mfprintf(oerr, "%s: FATAL: unable to create signal handlers: %s\n",
            argv[0], strerror(errno));
    MERO_EXIT(1);
}
</code></pre>

<p>/<em>*
 * Handler for SIGINT, SIGTERM and SIGQUIT.  This starts a graceful
 * shutdown of merovingian.</em>/
void  handler(int sig)
{</p>

<pre><code>char *signame = sigtostr(sig);
if (signame == NULL) {
    Mfprintf(stdout, "caught signal %d, starting shutdown sequence\n", sig);
} else {
    Mfprintf(stdout, "caught %s, starting shutdown sequence\n", signame);
}
_mero_keep_listening = 0;
</code></pre>

<p>}
{% endcodeblock %}
捕捉SIGHUP信号，处理是huphandler函数，重新读取配置文件
{% codeblock  lang:c %}</p>

<pre><code>sigemptyset(&amp;sa.sa_mask);
sa.sa_flags = 0;
sa.sa_handler = huphandler;
if (sigaction(SIGHUP, &amp;sa, NULL) == -1) {
    Mfprintf(oerr, "%s: FATAL: unable to create signal handlers: %s\n",
            argv[0], strerror(errno));
    MERO_EXIT(1);
}
</code></pre>

<p>/<em>*
 * Handler for SIGHUP, causes a re-read of the .merovingian_properties
 * file and the logfile to be reopened.
 </em>/
void huphandler(int sig)
{</p>

<pre><code>int t;
time_t now = time(NULL);
struct tm *tmp = localtime(&amp;now);
char mytime[20];
char *f;
confkeyval *kv;
</code></pre></blockquote>

<pre><code>(void)sig;

/* re-read properties, we're in our dbfarm */
readProps(_mero_props, ".");

/* check and trim the hash-algo from the passphrase for easy use
 * lateron */
kv = findConfKey(_mero_props, "passphrase");
if (kv-&gt;val != NULL) {
    char *h = kv-&gt;val + 1;
    if ((f = strchr(h, '}')) == NULL) {
        setConfVal(kv, NULL);
    } else {
        *f = '\0';
        if (strcmp(h, MONETDB5_PASSWDHASH) != 0) {
            setConfVal(kv, NULL);
        } else {
            setConfVal(kv, f + 1);
        }
    }
}

/* have to make sure the logger is not logging anything */
pthread_mutex_lock(&amp;_mero_topdp_lock);

strftime(mytime, sizeof(mytime), "%Y-%m-%d %H:%M:%S", tmp);

f = getConfVal(_mero_props, "logfile");
/* reopen (or open new) file */
t = open(f, O_WRONLY | O_APPEND | O_CREAT, S_IRUSR | S_IWUSR);
if (t == -1) {
    Mfprintf(stderr, "forced to ignore SIGHUP: unable to open "
            "'%s': %s\n", f, strerror(errno));
} else {
    Mfprintf(_mero_logfile, "%s END merovingian[" LLFMT "]: "
            "caught SIGHUP, closing logfile\n",
            mytime, (long long int)_mero_topdp-&gt;next-&gt;pid);
    fflush(_mero_logfile);
    _mero_topdp-&gt;out = _mero_topdp-&gt;err = t;
    _mero_logfile = fdopen(t, "a");
    Mfprintf(_mero_logfile, "%s BEG merovingian[" LLFMT "]: "
            "reopening logfile\n",
            mytime, (long long int)_mero_topdp-&gt;next-&gt;pid);
}

/* logger go ahead! */
pthread_mutex_unlock(&amp;_mero_topdp_lock);
</code></pre>

<p>}
{% endcodeblock %}</p>

<blockquote><p>捕捉SIGCHLD信号，处理childhandler，处理释放子进程的资源和清理。
{% codeblock  lang:c %}</p>

<pre><code>sa.sa_flags = SA_SIGINFO;
sigemptyset(&amp;sa.sa_mask);
sa.sa_sigaction = childhandler;
if (sigaction(SIGCHLD, &amp;sa, NULL) == -1) {
    Mfprintf(oerr, "%s: FATAL: unable to create signal handlers: %s\n",
            argv[0], strerror(errno));
    MERO_EXIT(1);
}
</code></pre>

<p>/<em><em>
 * Handles SIGCHLD signals, that is, signals that a parent receives
 * about its children.  This handler deals with terminated children, by
 * deregistering them from the internal administration (_mero_topdp)
 * with the necessary cleanup.
 </em>/
void  childhandler(int sig, siginfo_t </em>si, void *unused)
{</p>

<pre><code>dpair p, q;
</code></pre></blockquote>

<pre><code>(void)sig;
(void)unused;

/* wait for the child to get properly terminated, hopefully filling
 * in the siginfo struct on FreeBSD */
wait(NULL);

if (si-&gt;si_code != CLD_EXITED &amp;&amp;
        si-&gt;si_code != CLD_KILLED &amp;&amp;
        si-&gt;si_code != CLD_DUMPED)
{
    /* ignore traps, stops and continues, we only want terminations
     * of the client process */
    return;
}
pthread_mutex_lock(&amp;_mero_topdp_lock);

/* get the pid from the former child, and locate it in our list */
q = _mero_topdp-&gt;next;
p = q-&gt;next;
while (p != NULL) {
    if (p-&gt;pid == si-&gt;si_pid) {
        /* log everything that's still in the pipes */
        logFD(p-&gt;out, "MSG", p-&gt;dbname, (long long int)p-&gt;pid, _mero_logfile);
        /* remove from the list */
        q-&gt;next = p-&gt;next;
        /* close the descriptors */
        close(p-&gt;out);
        close(p-&gt;err);
        if (si-&gt;si_code == CLD_EXITED) {
            Mfprintf(stdout, "database '%s' (%lld) has exited with "
                    "exit status %d\n", p-&gt;dbname,
                    (long long int)p-&gt;pid, si-&gt;si_status);
        } else if (si-&gt;si_code == CLD_KILLED) {
            char *sigstr = sigtostr(si-&gt;si_status);
            char signum[8];
            if (sigstr == NULL) {
                snprintf(signum, 8, "%d", si-&gt;si_status);
                sigstr = signum;
            }
            Mfprintf(stdout, "database '%s' (%lld) was killed by signal "
                    "%s\n", p-&gt;dbname,
                    (long long int)p-&gt;pid, sigstr);
        } else if (si-&gt;si_code == CLD_DUMPED) {
            Mfprintf(stdout, "database '%s' (%lld) has crashed "
                    "(dumped core)\n", p-&gt;dbname,
                    (long long int)p-&gt;pid);
        }
        if (p-&gt;dbname)
            free(p-&gt;dbname);
        free(p);
        pthread_mutex_unlock(&amp;_mero_topdp_lock);
        return;
    }
    q = p;
    p = q-&gt;next;
}

pthread_mutex_unlock(&amp;_mero_topdp_lock);

Mfprintf(stdout, "received SIGCHLD from unknown child with pid %lld\n",
        (long long int)si-&gt;si_pid);
</code></pre>

<p>}
{% endcodeblock %}</p>
]]></content>
  </entry>
  
</feed>
